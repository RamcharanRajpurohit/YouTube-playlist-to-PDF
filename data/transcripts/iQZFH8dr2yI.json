{
  "video": {
    "video_id": "iQZFH8dr2yI",
    "title": "Lecture 9: Creating Input-Target data pairs using Python DataLoader",
    "duration": 3345.0,
    "index": 8
  },
  "segments": [
    {
      "text": "[Music]",
      "start": 0.0,
      "duration": 8.24
    },
    {
      "text": "hello everyone welcome to this lecture",
      "start": 5.319,
      "duration": 5.4
    },
    {
      "text": "in the build large language models from",
      "start": 8.24,
      "duration": 3.64
    },
    {
      "text": "scratch",
      "start": 10.719,
      "duration": 4.321
    },
    {
      "text": "Series in the previous lecture we took a",
      "start": 11.88,
      "duration": 7.68
    },
    {
      "text": "look at bite pair encoding and uh we saw",
      "start": 15.04,
      "duration": 6.96
    },
    {
      "text": "that how bite pair encoding algorithm",
      "start": 19.56,
      "duration": 4.68
    },
    {
      "text": "can be used for something which is",
      "start": 22.0,
      "duration": 5.4
    },
    {
      "text": "called as subword tokenization so we saw",
      "start": 24.24,
      "duration": 4.84
    },
    {
      "text": "the difference between word based",
      "start": 27.4,
      "duration": 3.719
    },
    {
      "text": "subword based and character based",
      "start": 29.08,
      "duration": 4.479
    },
    {
      "text": "tokenization and we looked in detail how",
      "start": 31.119,
      "duration": 6.401
    },
    {
      "text": "GPT models such as GPT 2 3 and 4 use the",
      "start": 33.559,
      "duration": 7.241
    },
    {
      "text": "bite pair encoding algorithm for",
      "start": 37.52,
      "duration": 5.28
    },
    {
      "text": "tokenization if you have not seen the",
      "start": 40.8,
      "duration": 4.48
    },
    {
      "text": "video for the previous lecture again I",
      "start": 42.8,
      "duration": 4.439
    },
    {
      "text": "would highly ENC encourage you to go",
      "start": 45.28,
      "duration": 3.52
    },
    {
      "text": "through this so that you will follow",
      "start": 47.239,
      "duration": 3.921
    },
    {
      "text": "along pretty well in this lecture if you",
      "start": 48.8,
      "duration": 4.079
    },
    {
      "text": "are coming to this playlist for the",
      "start": 51.16,
      "duration": 4.8
    },
    {
      "text": "first time welcome and uh we follow a",
      "start": 52.879,
      "duration": 4.921
    },
    {
      "text": "very specific style in this playlist",
      "start": 55.96,
      "duration": 3.759
    },
    {
      "text": "where we do a mix of writing on the",
      "start": 57.8,
      "duration": 4.759
    },
    {
      "text": "White board plus showing you everything",
      "start": 59.719,
      "duration": 5.12
    },
    {
      "text": "from scratch in the jupyter notebook",
      "start": 62.559,
      "duration": 4.961
    },
    {
      "text": "code editor so that the theoretical",
      "start": 64.839,
      "duration": 4.881
    },
    {
      "text": "understanding is also strong and the",
      "start": 67.52,
      "duration": 4.2
    },
    {
      "text": "coding background is also",
      "start": 69.72,
      "duration": 4.84
    },
    {
      "text": "strong up till now we have looked at",
      "start": 71.72,
      "duration": 5.6
    },
    {
      "text": "tokenization which is needed for large",
      "start": 74.56,
      "duration": 4.76
    },
    {
      "text": "language models so if you think of the",
      "start": 77.32,
      "duration": 4.08
    },
    {
      "text": "whole process we are currently at the",
      "start": 79.32,
      "duration": 4.479
    },
    {
      "text": "data pre-processing stage before the",
      "start": 81.4,
      "duration": 4.88
    },
    {
      "text": "data is given for the llm training in",
      "start": 83.799,
      "duration": 4.64
    },
    {
      "text": "the pre-processing the first step is",
      "start": 86.28,
      "duration": 4.879
    },
    {
      "text": "tokenization then we come to something",
      "start": 88.439,
      "duration": 4.881
    },
    {
      "text": "called Vector embeddings we have not",
      "start": 91.159,
      "duration": 4.92
    },
    {
      "text": "seen Vector embeddings yet uh and then",
      "start": 93.32,
      "duration": 4.36
    },
    {
      "text": "after that we feed these Vector",
      "start": 96.079,
      "duration": 5.36
    },
    {
      "text": "embeddings to the uh training or for the",
      "start": 97.68,
      "duration": 4.759
    },
    {
      "text": "training",
      "start": 101.439,
      "duration": 3.36
    },
    {
      "text": "process before we come to Vector",
      "start": 102.439,
      "duration": 4.28
    },
    {
      "text": "embeddings there is one very important",
      "start": 104.799,
      "duration": 4.28
    },
    {
      "text": "lecture which we need to cover and that",
      "start": 106.719,
      "duration": 4.961
    },
    {
      "text": "is the topic of today's lecture creating",
      "start": 109.079,
      "duration": 5.761
    },
    {
      "text": "input Target pairs essentially input",
      "start": 111.68,
      "duration": 5.479
    },
    {
      "text": "output pairs if you look at other",
      "start": 114.84,
      "duration": 3.919
    },
    {
      "text": "machine learning tasks such as",
      "start": 117.159,
      "duration": 4.521
    },
    {
      "text": "classification ation it's usually",
      "start": 118.759,
      "duration": 4.881
    },
    {
      "text": "usually very clear right what is the",
      "start": 121.68,
      "duration": 4.119
    },
    {
      "text": "input and what is the output if you want",
      "start": 123.64,
      "duration": 4.24
    },
    {
      "text": "to distinguish between cats and dogs",
      "start": 125.799,
      "duration": 4.88
    },
    {
      "text": "from images the images of cats and the",
      "start": 127.88,
      "duration": 6.16
    },
    {
      "text": "images of dogs will be input and whether",
      "start": 130.679,
      "duration": 5.2
    },
    {
      "text": "it's a cat or whether it's a dog will be",
      "start": 134.04,
      "duration": 4.72
    },
    {
      "text": "the output if you consider a regression",
      "start": 135.879,
      "duration": 4.961
    },
    {
      "text": "problem on the other hand let's say if",
      "start": 138.76,
      "duration": 4.199
    },
    {
      "text": "you want to predict the price of a house",
      "start": 140.84,
      "duration": 4.84
    },
    {
      "text": "B based on its area the area of the",
      "start": 142.959,
      "duration": 5.081
    },
    {
      "text": "houses is the input and the price is the",
      "start": 145.68,
      "duration": 5.04
    },
    {
      "text": "output so creating the input output",
      "start": 148.04,
      "duration": 4.479
    },
    {
      "text": "pairs or the input Target pairs is",
      "start": 150.72,
      "duration": 4.519
    },
    {
      "text": "pretty easy for large language models we",
      "start": 152.519,
      "duration": 4.841
    },
    {
      "text": "use a specific technique for creating",
      "start": 155.239,
      "duration": 4.321
    },
    {
      "text": "these pairs and it's very important to",
      "start": 157.36,
      "duration": 4.68
    },
    {
      "text": "devote a separate lecture for you to",
      "start": 159.56,
      "duration": 4.48
    },
    {
      "text": "understand this so let's get started",
      "start": 162.04,
      "duration": 3.279
    },
    {
      "text": "with today's",
      "start": 164.04,
      "duration": 4.24
    },
    {
      "text": "lecture as I mentioned before now only",
      "start": 165.319,
      "duration": 5.041
    },
    {
      "text": "one last step is remaining before we",
      "start": 168.28,
      "duration": 4.76
    },
    {
      "text": "move to creating Vector embeddings which",
      "start": 170.36,
      "duration": 4.959
    },
    {
      "text": "will then be fed to training the large",
      "start": 173.04,
      "duration": 4.919
    },
    {
      "text": "language model and then last and then",
      "start": 175.319,
      "duration": 4.521
    },
    {
      "text": "that last step is essentially create",
      "start": 177.959,
      "duration": 4.92
    },
    {
      "text": "getting the input Target pairs so first",
      "start": 179.84,
      "duration": 5.92
    },
    {
      "text": "when I say input Target pairs what do I",
      "start": 182.879,
      "duration": 4.92
    },
    {
      "text": "mean and what do input Target pairs",
      "start": 185.76,
      "duration": 8.0
    },
    {
      "text": "looks like so let's say uh this is my uh",
      "start": 187.799,
      "duration": 8.36
    },
    {
      "text": "sentence right which is the text sample",
      "start": 193.76,
      "duration": 7.36
    },
    {
      "text": "llms learn to predict one word at a time",
      "start": 196.159,
      "duration": 9.921
    },
    {
      "text": "so the blocks which are marked in blue",
      "start": 201.12,
      "duration": 8.119
    },
    {
      "text": "will be the input to the llm and the",
      "start": 206.08,
      "duration": 6.12
    },
    {
      "text": "block which are marked in red will be",
      "start": 209.239,
      "duration": 6.041
    },
    {
      "text": "the Target or the output which the llms",
      "start": 212.2,
      "duration": 4.28
    },
    {
      "text": "have to",
      "start": 215.28,
      "duration": 3.76
    },
    {
      "text": "learn and why are there these different",
      "start": 216.48,
      "duration": 5.959
    },
    {
      "text": "rows so these are different iterations",
      "start": 219.04,
      "duration": 5.399
    },
    {
      "text": "let's look at the first iteration in the",
      "start": 222.439,
      "duration": 5.641
    },
    {
      "text": "first iteration the input is llm and the",
      "start": 224.439,
      "duration": 6.241
    },
    {
      "text": "based on this input the out uh llm has",
      "start": 228.08,
      "duration": 4.6
    },
    {
      "text": "to learn the output which is the learn",
      "start": 230.68,
      "duration": 4.759
    },
    {
      "text": "so the next word is always the output",
      "start": 232.68,
      "duration": 4.72
    },
    {
      "text": "whatever comes after the prediction is",
      "start": 235.439,
      "duration": 5.041
    },
    {
      "text": "masked or it's not shown to the llm",
      "start": 237.4,
      "duration": 5.399
    },
    {
      "text": "this is what happens in iteration number",
      "start": 240.48,
      "duration": 5.0
    },
    {
      "text": "one now let's look at iteration number",
      "start": 242.799,
      "duration": 6.72
    },
    {
      "text": "two so learn which was the output or the",
      "start": 245.48,
      "duration": 6.36
    },
    {
      "text": "Target in the first iteration now is a",
      "start": 249.519,
      "duration": 4.521
    },
    {
      "text": "part of the input so in the second",
      "start": 251.84,
      "duration": 5.959
    },
    {
      "text": "iteration llms learn that is the input",
      "start": 254.04,
      "duration": 6.36
    },
    {
      "text": "and two is the target that's the target",
      "start": 257.799,
      "duration": 5.281
    },
    {
      "text": "pair that's the second",
      "start": 260.4,
      "duration": 5.799
    },
    {
      "text": "iteration in the third iteration two",
      "start": 263.08,
      "duration": 4.64
    },
    {
      "text": "which was the output of the previous",
      "start": 266.199,
      "duration": 3.601
    },
    {
      "text": "iteration now becomes the input so so",
      "start": 267.72,
      "duration": 4.56
    },
    {
      "text": "llms learn to is the input in the third",
      "start": 269.8,
      "duration": 5.92
    },
    {
      "text": "iteration and predict is the output I",
      "start": 272.28,
      "duration": 5.04
    },
    {
      "text": "hope you have started understanding the",
      "start": 275.72,
      "duration": 4.479
    },
    {
      "text": "pattern now in every iteration there is",
      "start": 277.32,
      "duration": 5.52
    },
    {
      "text": "only the next word which is the output",
      "start": 280.199,
      "duration": 4.56
    },
    {
      "text": "and whatever comes before that is the",
      "start": 282.84,
      "duration": 5.76
    },
    {
      "text": "input these are the input Target",
      "start": 284.759,
      "duration": 7.041
    },
    {
      "text": "pairs that's very important to remember",
      "start": 288.6,
      "duration": 6.24
    },
    {
      "text": "so uh here also you'll see that llms",
      "start": 291.8,
      "duration": 5.16
    },
    {
      "text": "learn to predict is the input and one is",
      "start": 294.84,
      "duration": 4.199
    },
    {
      "text": "the output so at every stage of the",
      "start": 296.96,
      "duration": 5.64
    },
    {
      "text": "iteration process uh llms have input",
      "start": 299.039,
      "duration": 6.041
    },
    {
      "text": "which is the part of the sentence up",
      "start": 302.6,
      "duration": 4.28
    },
    {
      "text": "till the word which needs to be",
      "start": 305.08,
      "duration": 4.679
    },
    {
      "text": "predicted and the word which needs to be",
      "start": 306.88,
      "duration": 6.48
    },
    {
      "text": "predicted that is essentially the",
      "start": 309.759,
      "duration": 6.121
    },
    {
      "text": "output this this figure which I'm saying",
      "start": 313.36,
      "duration": 4.72
    },
    {
      "text": "is just for illustration purposes in",
      "start": 315.88,
      "duration": 3.879
    },
    {
      "text": "today's lecture we'll learn something",
      "start": 318.08,
      "duration": 4.08
    },
    {
      "text": "about context length which means how",
      "start": 319.759,
      "duration": 4.841
    },
    {
      "text": "many words are given as the input the",
      "start": 322.16,
      "duration": 4.72
    },
    {
      "text": "output length is always one one word",
      "start": 324.6,
      "duration": 4.24
    },
    {
      "text": "will be predicted but we can essentially",
      "start": 326.88,
      "duration": 4.599
    },
    {
      "text": "choose the input context",
      "start": 328.84,
      "duration": 5.479
    },
    {
      "text": "length now uh in every",
      "start": 331.479,
      "duration": 5.481
    },
    {
      "text": "iteration The Words which are after the",
      "start": 334.319,
      "duration": 5.6
    },
    {
      "text": "target are essentially masked so the",
      "start": 336.96,
      "duration": 5.32
    },
    {
      "text": "llms cannot access The Words which are",
      "start": 339.919,
      "duration": 4.641
    },
    {
      "text": "past the target so there are two things",
      "start": 342.28,
      "duration": 3.84
    },
    {
      "text": "to remember here the first thing to",
      "start": 344.56,
      "duration": 3.359
    },
    {
      "text": "remember is that within the sentence",
      "start": 346.12,
      "duration": 3.76
    },
    {
      "text": "itself we break down the sentence into",
      "start": 347.919,
      "duration": 4.12
    },
    {
      "text": "input and a Target which is the next",
      "start": 349.88,
      "duration": 4.96
    },
    {
      "text": "word uh then in the second thing to",
      "start": 352.039,
      "duration": 4.321
    },
    {
      "text": "remember is that in subsequent",
      "start": 354.84,
      "duration": 3.52
    },
    {
      "text": "iterations whatever was the output in",
      "start": 356.36,
      "duration": 4.2
    },
    {
      "text": "the previous iteration then becomes the",
      "start": 358.36,
      "duration": 5.64
    },
    {
      "text": "input so this is a auto regressive model",
      "start": 360.56,
      "duration": 5.8
    },
    {
      "text": "why Auto regressive because the output",
      "start": 364.0,
      "duration": 4.16
    },
    {
      "text": "of the first iteration becomes an input",
      "start": 366.36,
      "duration": 4.119
    },
    {
      "text": "of the next iteration like let's look at",
      "start": 368.16,
      "duration": 4.759
    },
    {
      "text": "these two iterations in in this",
      "start": 370.479,
      "duration": 4.201
    },
    {
      "text": "iteration let me show it with a",
      "start": 372.919,
      "duration": 3.961
    },
    {
      "text": "different color so that it becomes easy",
      "start": 374.68,
      "duration": 5.44
    },
    {
      "text": "in this iteration one the result one was",
      "start": 376.88,
      "duration": 5.159
    },
    {
      "text": "an output right but see in this",
      "start": 380.12,
      "duration": 4.4
    },
    {
      "text": "iteration one is now a part of the input",
      "start": 382.039,
      "duration": 4.321
    },
    {
      "text": "and then the next word is the output so",
      "start": 384.52,
      "duration": 3.959
    },
    {
      "text": "it's called an auto regressive and it's",
      "start": 386.36,
      "duration": 5.92
    },
    {
      "text": "also called a self-supervised learning",
      "start": 388.479,
      "duration": 5.801
    },
    {
      "text": "or you can think of it as unsupervised",
      "start": 392.28,
      "duration": 3.84
    },
    {
      "text": "learning itself because we are not",
      "start": 394.28,
      "duration": 4.0
    },
    {
      "text": "labeling the input and the output the",
      "start": 396.12,
      "duration": 3.88
    },
    {
      "text": "sentence structure",
      "start": 398.28,
      "duration": 5.359
    },
    {
      "text": "itself uh is used to predict or is used",
      "start": 400.0,
      "duration": 5.24
    },
    {
      "text": "to determine what is the input and the",
      "start": 403.639,
      "duration": 3.641
    },
    {
      "text": "output we do not have to do any special",
      "start": 405.24,
      "duration": 4.679
    },
    {
      "text": "labeling so in cats and dogs we have to",
      "start": 407.28,
      "duration": 4.479
    },
    {
      "text": "manually label this is a cat this is a",
      "start": 409.919,
      "duration": 4.0
    },
    {
      "text": "dog right for the image classification",
      "start": 411.759,
      "duration": 4.681
    },
    {
      "text": "but here to create the input Target",
      "start": 413.919,
      "duration": 4.441
    },
    {
      "text": "pairs we don't have to say that look",
      "start": 416.44,
      "duration": 4.319
    },
    {
      "text": "this label this as the input label this",
      "start": 418.36,
      "duration": 4.239
    },
    {
      "text": "as the output we'll just write a simple",
      "start": 420.759,
      "duration": 4.081
    },
    {
      "text": "code which utilizes the sentence",
      "start": 422.599,
      "duration": 4.481
    },
    {
      "text": "structure itself and breaks down the",
      "start": 424.84,
      "duration": 4.68
    },
    {
      "text": "sentence into input and the output so",
      "start": 427.08,
      "duration": 4.399
    },
    {
      "text": "this is also an example of unsupervised",
      "start": 429.52,
      "duration": 3.84
    },
    {
      "text": "learning and it's also called Auto",
      "start": 431.479,
      "duration": 3.921
    },
    {
      "text": "regressive I hope you have understood",
      "start": 433.36,
      "duration": 3.32
    },
    {
      "text": "these two",
      "start": 435.4,
      "duration": 4.12
    },
    {
      "text": "concepts so in pre-training we always do",
      "start": 436.68,
      "duration": 4.359
    },
    {
      "text": "unsupervised learning because the",
      "start": 439.52,
      "duration": 3.48
    },
    {
      "text": "sentence structure is exploited to",
      "start": 441.039,
      "duration": 4.0
    },
    {
      "text": "create input output pairs or input",
      "start": 443.0,
      "duration": 5.08
    },
    {
      "text": "Target pairs so I hope you have",
      "start": 445.039,
      "duration": 5.88
    },
    {
      "text": "understood how the the input Target",
      "start": 448.08,
      "duration": 4.679
    },
    {
      "text": "pairs look like and we are going to",
      "start": 450.919,
      "duration": 5.56
    },
    {
      "text": "create this in today's lecture in Python",
      "start": 452.759,
      "duration": 5.641
    },
    {
      "text": "uh if you understand up till this it's",
      "start": 456.479,
      "duration": 3.84
    },
    {
      "text": "actually pretty easy to code it out in",
      "start": 458.4,
      "duration": 4.28
    },
    {
      "text": "Python but I have I feel that students",
      "start": 460.319,
      "duration": 3.961
    },
    {
      "text": "don't really understand this part",
      "start": 462.68,
      "duration": 3.84
    },
    {
      "text": "intuitively and and hence they find the",
      "start": 464.28,
      "duration": 4.599
    },
    {
      "text": "coding part of it a bit",
      "start": 466.52,
      "duration": 4.799
    },
    {
      "text": "difficult okay now I want to mention a",
      "start": 468.879,
      "duration": 5.081
    },
    {
      "text": "few things uh which I've just which just",
      "start": 471.319,
      "duration": 4.241
    },
    {
      "text": "serve as a summary of what all I",
      "start": 473.96,
      "duration": 4.6
    },
    {
      "text": "explained up till now the first thing is",
      "start": 475.56,
      "duration": 4.599
    },
    {
      "text": "what we are essentially doing here is",
      "start": 478.56,
      "duration": 4.96
    },
    {
      "text": "that we are given a text sample and uh",
      "start": 480.159,
      "duration": 5.201
    },
    {
      "text": "based on the text sample we are",
      "start": 483.52,
      "duration": 5.04
    },
    {
      "text": "extracting input blocks that serve as",
      "start": 485.36,
      "duration": 7.119
    },
    {
      "text": "the input to the llm correct and the llm",
      "start": 488.56,
      "duration": 6.28
    },
    {
      "text": "prediction task during the training is",
      "start": 492.479,
      "duration": 4.56
    },
    {
      "text": "to predict the next word that follows",
      "start": 494.84,
      "duration": 4.759
    },
    {
      "text": "the input block so for example if you're",
      "start": 497.039,
      "duration": 5.521
    },
    {
      "text": "looking at this input block the llm task",
      "start": 499.599,
      "duration": 5.04
    },
    {
      "text": "is to predict the output or the next",
      "start": 502.56,
      "duration": 3.72
    },
    {
      "text": "word based on this",
      "start": 504.639,
      "duration": 3.921
    },
    {
      "text": "input uh and that's what the llm is",
      "start": 506.28,
      "duration": 4.12
    },
    {
      "text": "trained for",
      "start": 508.56,
      "duration": 3.959
    },
    {
      "text": "and the last point to remember is that",
      "start": 510.4,
      "duration": 4.48
    },
    {
      "text": "during the training process we will mask",
      "start": 512.519,
      "duration": 4.561
    },
    {
      "text": "out all the words that are past the",
      "start": 514.88,
      "duration": 4.92
    },
    {
      "text": "target so in every iteration the target",
      "start": 517.08,
      "duration": 4.36
    },
    {
      "text": "is the target word right like in this",
      "start": 519.8,
      "duration": 4.119
    },
    {
      "text": "iteration time or let me take an earlier",
      "start": 521.44,
      "duration": 4.519
    },
    {
      "text": "iteration in this iteration two is the",
      "start": 523.919,
      "duration": 4.04
    },
    {
      "text": "target so when we are doing this",
      "start": 525.959,
      "duration": 3.961
    },
    {
      "text": "iteration the llm does not see anything",
      "start": 527.959,
      "duration": 4.081
    },
    {
      "text": "which comes after two so this part is",
      "start": 529.92,
      "duration": 4.64
    },
    {
      "text": "essentially",
      "start": 532.04,
      "duration": 2.52
    },
    {
      "text": "masked and we'll see how to implement",
      "start": 535.48,
      "duration": 5.4
    },
    {
      "text": "all of these features in code",
      "start": 537.88,
      "duration": 5.36
    },
    {
      "text": "Okay so until now I just wanted to",
      "start": 540.88,
      "duration": 4.28
    },
    {
      "text": "explain what is the purpose and what is",
      "start": 543.24,
      "duration": 4.279
    },
    {
      "text": "the aim of today's lecture and now we",
      "start": 545.16,
      "duration": 4.32
    },
    {
      "text": "are going to code the input Target pairs",
      "start": 547.519,
      "duration": 4.241
    },
    {
      "text": "in Python so I hope you are ready for",
      "start": 549.48,
      "duration": 5.799
    },
    {
      "text": "this coding so let's get started with",
      "start": 551.76,
      "duration": 7.079
    },
    {
      "text": "coding great so this coding section I've",
      "start": 555.279,
      "duration": 6.401
    },
    {
      "text": "have titled creating input Target pairs",
      "start": 558.839,
      "duration": 5.641
    },
    {
      "text": "as always I'll be sharing this Jupiter",
      "start": 561.68,
      "duration": 4.88
    },
    {
      "text": "notebook code also with you along with",
      "start": 564.48,
      "duration": 4.52
    },
    {
      "text": "the video so that you can run the code",
      "start": 566.56,
      "duration": 3.56
    },
    {
      "text": "and check check whether you have",
      "start": 569.0,
      "duration": 3.88
    },
    {
      "text": "understood the concept or not",
      "start": 570.12,
      "duration": 5.52
    },
    {
      "text": "yourself so in this section we are going",
      "start": 572.88,
      "duration": 5.639
    },
    {
      "text": "to implement a data loader that fetches",
      "start": 575.64,
      "duration": 5.96
    },
    {
      "text": "the input Target pairs using a sliding",
      "start": 578.519,
      "duration": 5.44
    },
    {
      "text": "window approach so there are two parts",
      "start": 581.6,
      "duration": 3.919
    },
    {
      "text": "of this sentence which might be",
      "start": 583.959,
      "duration": 4.761
    },
    {
      "text": "confusing to you what is data loader",
      "start": 585.519,
      "duration": 4.841
    },
    {
      "text": "that's part number one and what is the",
      "start": 588.72,
      "duration": 3.4
    },
    {
      "text": "sliding window approach that's part",
      "start": 590.36,
      "duration": 4.28
    },
    {
      "text": "number two don't worry I'll explain to",
      "start": 592.12,
      "duration": 4.48
    },
    {
      "text": "you both of these in a lot of",
      "start": 594.64,
      "duration": 4.4
    },
    {
      "text": "detail uh to get started what we will",
      "start": 596.6,
      "duration": 5.32
    },
    {
      "text": "initi do is that we'll take the whole",
      "start": 599.04,
      "duration": 5.56
    },
    {
      "text": "the verdict short story so remember our",
      "start": 601.92,
      "duration": 5.64
    },
    {
      "text": "data set for this entire coding Journey",
      "start": 604.6,
      "duration": 5.2
    },
    {
      "text": "for this entire playlist is this short",
      "start": 607.56,
      "duration": 5.32
    },
    {
      "text": "story The Verdict let me show you uh how",
      "start": 609.8,
      "duration": 4.8
    },
    {
      "text": "it actually looks",
      "start": 612.88,
      "duration": 4.48
    },
    {
      "text": "like so this is the short story called",
      "start": 614.6,
      "duration": 4.88
    },
    {
      "text": "The Verdict this is the data set which",
      "start": 617.36,
      "duration": 4.159
    },
    {
      "text": "we have been using I think this was",
      "start": 619.48,
      "duration": 4.44
    },
    {
      "text": "published in uh so let me check the",
      "start": 621.519,
      "duration": 6.201
    },
    {
      "text": "verdict edit won it was published in",
      "start": 623.92,
      "duration": 6.159
    },
    {
      "text": "1908 and we are using using this as the",
      "start": 627.72,
      "duration": 5.08
    },
    {
      "text": "data set it's a toy data set but it's",
      "start": 630.079,
      "duration": 4.601
    },
    {
      "text": "important because whatever we learn",
      "start": 632.8,
      "duration": 4.0
    },
    {
      "text": "right now it scales exactly the same way",
      "start": 634.68,
      "duration": 5.24
    },
    {
      "text": "for larger data sets as well so we are",
      "start": 636.8,
      "duration": 5.039
    },
    {
      "text": "going to use this data set and remember",
      "start": 639.92,
      "duration": 3.64
    },
    {
      "text": "in the last lecture we looked at the",
      "start": 641.839,
      "duration": 4.12
    },
    {
      "text": "bite pair encoding tokenizer we are",
      "start": 643.56,
      "duration": 4.64
    },
    {
      "text": "going to encode this entire text using",
      "start": 645.959,
      "duration": 4.481
    },
    {
      "text": "the bite pair encoding tokenizer it's a",
      "start": 648.2,
      "duration": 5.12
    },
    {
      "text": "subword tokenizer so the tokens Can Be",
      "start": 650.44,
      "duration": 4.8
    },
    {
      "text": "characters the token can be words the",
      "start": 653.32,
      "duration": 4.72
    },
    {
      "text": "tokens can be subwords as well so if you",
      "start": 655.24,
      "duration": 4.36
    },
    {
      "text": "if you are not familiar with the bite",
      "start": 658.04,
      "duration": 4.0
    },
    {
      "text": "pair encoder please look at the previous",
      "start": 659.6,
      "duration": 4.16
    },
    {
      "text": "lecture which we have",
      "start": 662.04,
      "duration": 4.799
    },
    {
      "text": "covered great so we have uh defined the",
      "start": 663.76,
      "duration": 5.04
    },
    {
      "text": "tokenizer already which is the bite pair",
      "start": 666.839,
      "duration": 4.761
    },
    {
      "text": "encoder tokenizer and what we'll be",
      "start": 668.8,
      "duration": 5.64
    },
    {
      "text": "first doing is we will read the entire",
      "start": 671.6,
      "duration": 5.08
    },
    {
      "text": "data set and store it in a variable",
      "start": 674.44,
      "duration": 4.88
    },
    {
      "text": "called raw text and then we will encode",
      "start": 676.68,
      "duration": 4.839
    },
    {
      "text": "the entire raw text remember what an",
      "start": 679.32,
      "duration": 4.36
    },
    {
      "text": "encoder does is takes this text and",
      "start": 681.519,
      "duration": 5.681
    },
    {
      "text": "converts it into token IDs and let us",
      "start": 683.68,
      "duration": 5.399
    },
    {
      "text": "actually run this right now so I ran",
      "start": 687.2,
      "duration": 4.439
    },
    {
      "text": "this right now and you will see that uh",
      "start": 689.079,
      "duration": 4.0
    },
    {
      "text": "I've have printed out the length of the",
      "start": 691.639,
      "duration": 3.801
    },
    {
      "text": "encoded text which means it's",
      "start": 693.079,
      "duration": 4.88
    },
    {
      "text": "5145 that means the vocabulary size",
      "start": 695.44,
      "duration": 5.079
    },
    {
      "text": "which we have is 5145 what does a",
      "start": 697.959,
      "duration": 4.841
    },
    {
      "text": "vocabulary mean well we covered this in",
      "start": 700.519,
      "duration": 4.0
    },
    {
      "text": "the previous lecture but let me show it",
      "start": 702.8,
      "duration": 4.68
    },
    {
      "text": "to you again a vocabulary essentially",
      "start": 704.519,
      "duration": 5.76
    },
    {
      "text": "looks something like",
      "start": 707.48,
      "duration": 4.4
    },
    {
      "text": "this",
      "start": 710.279,
      "duration": 5.0
    },
    {
      "text": "uh yeah so this is",
      "start": 711.88,
      "duration": 6.56
    },
    {
      "text": "how let me go to the yeah this is how a",
      "start": 715.279,
      "duration": 5.12
    },
    {
      "text": "vocabulary looks like like essentially",
      "start": 718.44,
      "duration": 4.24
    },
    {
      "text": "we'll have different tokens and to every",
      "start": 720.399,
      "duration": 6.081
    },
    {
      "text": "token a token ID will be uh attached so",
      "start": 722.68,
      "duration": 5.52
    },
    {
      "text": "vocabulary is essentially dictionary",
      "start": 726.48,
      "duration": 4.32
    },
    {
      "text": "which maps The Tokens into token IDs",
      "start": 728.2,
      "duration": 4.199
    },
    {
      "text": "remember since we are using the bite",
      "start": 730.8,
      "duration": 3.839
    },
    {
      "text": "pair encoder the tokens won't be words",
      "start": 732.399,
      "duration": 4.361
    },
    {
      "text": "but they can be subwords or characters",
      "start": 734.639,
      "duration": 6.081
    },
    {
      "text": "also so essentially what this size 5145",
      "start": 736.76,
      "duration": 7.16
    },
    {
      "text": "conveys is that our vocabulary for the",
      "start": 740.72,
      "duration": 6.119
    },
    {
      "text": "for this text which we have as the data",
      "start": 743.92,
      "duration": 5.919
    },
    {
      "text": "set has the length of 514 5 which means",
      "start": 746.839,
      "duration": 5.761
    },
    {
      "text": "we have 5145 tokens and corresponding",
      "start": 749.839,
      "duration": 4.881
    },
    {
      "text": "token IDs",
      "start": 752.6,
      "duration": 5.039
    },
    {
      "text": "great so uh I have just written this in",
      "start": 754.72,
      "duration": 5.32
    },
    {
      "text": "blue executing the code above will",
      "start": 757.639,
      "duration": 5.241
    },
    {
      "text": "return 5145 that is the total number of",
      "start": 760.04,
      "duration": 4.799
    },
    {
      "text": "tokens in the training set after",
      "start": 762.88,
      "duration": 4.88
    },
    {
      "text": "applying the bite PA encoding tokenizer",
      "start": 764.839,
      "duration": 5.56
    },
    {
      "text": "great so what I'm going to demonstrate",
      "start": 767.76,
      "duration": 4.48
    },
    {
      "text": "right now to you is just I'm going to",
      "start": 770.399,
      "duration": 5.601
    },
    {
      "text": "look at the first uh so what I'm going",
      "start": 772.24,
      "duration": 6.12
    },
    {
      "text": "to do as I'm going to remove the first",
      "start": 776.0,
      "duration": 4.639
    },
    {
      "text": "50 tokens for the from the data set just",
      "start": 778.36,
      "duration": 4.279
    },
    {
      "text": "so that the demonstration becomes a bit",
      "start": 780.639,
      "duration": 4.961
    },
    {
      "text": "better uh after you remove the initial",
      "start": 782.639,
      "duration": 5.401
    },
    {
      "text": "50 tokens it results in a slightly more",
      "start": 785.6,
      "duration": 4.919
    },
    {
      "text": "interesting text passage you can keep",
      "start": 788.04,
      "duration": 4.44
    },
    {
      "text": "the entire tokens as well just to make",
      "start": 790.519,
      "duration": 4.081
    },
    {
      "text": "the lecture more interesting what I'm",
      "start": 792.48,
      "duration": 5.64
    },
    {
      "text": "going to do here is that the encoded",
      "start": 794.6,
      "duration": 5.76
    },
    {
      "text": "tokens were in ENC or encoded unders",
      "start": 798.12,
      "duration": 4.399
    },
    {
      "text": "scroll text so I'm going to Define one",
      "start": 800.36,
      "duration": 3.919
    },
    {
      "text": "more variable called called encoded",
      "start": 802.519,
      "duration": 4.44
    },
    {
      "text": "undor sample which just removes the",
      "start": 804.279,
      "duration": 5.641
    },
    {
      "text": "first 50 tokens from the data set",
      "start": 806.959,
      "duration": 6.961
    },
    {
      "text": "great now uh first I what I want you all",
      "start": 809.92,
      "duration": 6.359
    },
    {
      "text": "to do is I want you to pause here for a",
      "start": 813.92,
      "duration": 5.479
    },
    {
      "text": "moment and think about this question",
      "start": 816.279,
      "duration": 5.721
    },
    {
      "text": "yourself uh think about the question",
      "start": 819.399,
      "duration": 4.44
    },
    {
      "text": "that let's say you are given this data",
      "start": 822.0,
      "duration": 5.839
    },
    {
      "text": "set right now and you you'll I hope you",
      "start": 823.839,
      "duration": 5.881
    },
    {
      "text": "understood this input output Target",
      "start": 827.839,
      "duration": 3.92
    },
    {
      "text": "pairs which I mentioned what's the",
      "start": 829.72,
      "duration": 4.16
    },
    {
      "text": "simplest thing which comes to your mind",
      "start": 831.759,
      "duration": 5.0
    },
    {
      "text": "how can you convert this data set into",
      "start": 833.88,
      "duration": 5.84
    },
    {
      "text": "such kind of uh input output Target",
      "start": 836.759,
      "duration": 5.481
    },
    {
      "text": "pairs what will you need to make this",
      "start": 839.72,
      "duration": 5.799
    },
    {
      "text": "conversion can you think about it a bit",
      "start": 842.24,
      "duration": 5.2
    },
    {
      "text": "think about the simplest way don't think",
      "start": 845.519,
      "duration": 4.161
    },
    {
      "text": "about complex algorithms anything like",
      "start": 847.44,
      "duration": 4.24
    },
    {
      "text": "that what is the simplest thing which",
      "start": 849.68,
      "duration": 4.68
    },
    {
      "text": "comes to your mind you can pause the",
      "start": 851.68,
      "duration": 4.959
    },
    {
      "text": "video here for some time because if you",
      "start": 854.36,
      "duration": 5.96
    },
    {
      "text": "answer it it will really improve your",
      "start": 856.639,
      "duration": 6.12
    },
    {
      "text": "understanding so let me reveal the",
      "start": 860.32,
      "duration": 5.68
    },
    {
      "text": "answer now one of the easiest and most",
      "start": 862.759,
      "duration": 6.361
    },
    {
      "text": "intuitive ways to create the input Ty",
      "start": 866.0,
      "duration": 5.12
    },
    {
      "text": "Target pairs for the next word",
      "start": 869.12,
      "duration": 4.839
    },
    {
      "text": "prediction task is to create two",
      "start": 871.12,
      "duration": 6.88
    },
    {
      "text": "variables X and Y where X contains the",
      "start": 873.959,
      "duration": 7.281
    },
    {
      "text": "input tokens and Y contains the targets",
      "start": 878.0,
      "duration": 5.079
    },
    {
      "text": "which are essentially the input shifted",
      "start": 881.24,
      "duration": 5.2
    },
    {
      "text": "by one so let me explain to you how this",
      "start": 883.079,
      "duration": 4.801
    },
    {
      "text": "logic",
      "start": 886.44,
      "duration": 4.28
    },
    {
      "text": "works okay so what do we exactly need",
      "start": 887.88,
      "duration": 6.639
    },
    {
      "text": "here let's say if uh let's say if my",
      "start": 890.72,
      "duration": 8.76
    },
    {
      "text": "input is 1 2 3 and 4 let's say say if my",
      "start": 894.519,
      "duration": 8.401
    },
    {
      "text": "input is this I want my output array",
      "start": 899.48,
      "duration": 6.08
    },
    {
      "text": "let's say if this is my input array X I",
      "start": 902.92,
      "duration": 5.12
    },
    {
      "text": "want my output array to be looking",
      "start": 905.56,
      "duration": 7.68
    },
    {
      "text": "something like 2 3 4 and",
      "start": 908.04,
      "duration": 9.039
    },
    {
      "text": "5 so what I have done here exactly is",
      "start": 913.24,
      "duration": 6.64
    },
    {
      "text": "that if one is the",
      "start": 917.079,
      "duration": 5.961
    },
    {
      "text": "input two should be the output it's very",
      "start": 919.88,
      "duration": 5.84
    },
    {
      "text": "similar here if llm is the input learn",
      "start": 923.04,
      "duration": 5.52
    },
    {
      "text": "should be the output correct if one and",
      "start": 925.72,
      "duration": 5.4
    },
    {
      "text": "two is the input then three should be",
      "start": 928.56,
      "duration": 5.92
    },
    {
      "text": "the output which means that if llm learn",
      "start": 931.12,
      "duration": 5.44
    },
    {
      "text": "is the input then two should be the",
      "start": 934.48,
      "duration": 6.839
    },
    {
      "text": "output if 1 2 3 are the input which",
      "start": 936.56,
      "duration": 7.6
    },
    {
      "text": "means that if llms learn two is the",
      "start": 941.319,
      "duration": 5.481
    },
    {
      "text": "input then the output should be four",
      "start": 944.16,
      "duration": 4.84
    },
    {
      "text": "which means that predict should be the",
      "start": 946.8,
      "duration": 6.519
    },
    {
      "text": "output and then finally if 1 2 3 4 if",
      "start": 949.0,
      "duration": 6.24
    },
    {
      "text": "all of these four words are the input",
      "start": 953.319,
      "duration": 4.041
    },
    {
      "text": "then five should be the output which",
      "start": 955.24,
      "duration": 5.12
    },
    {
      "text": "means that if llm learn to predict is",
      "start": 957.36,
      "duration": 5.12
    },
    {
      "text": "the input then the output should be",
      "start": 960.36,
      "duration": 3.479
    },
    {
      "text": "equal to",
      "start": 962.48,
      "duration": 3.76
    },
    {
      "text": "one this is what I actually want to",
      "start": 963.839,
      "duration": 4.841
    },
    {
      "text": "create and how do I determine the size",
      "start": 966.24,
      "duration": 5.159
    },
    {
      "text": "of this uh why do why did I take the",
      "start": 968.68,
      "duration": 4.839
    },
    {
      "text": "input size X to be four and the output",
      "start": 971.399,
      "duration": 4.401
    },
    {
      "text": "size to be four so basically that is",
      "start": 973.519,
      "duration": 5.081
    },
    {
      "text": "called as the context size the context",
      "start": 975.8,
      "duration": 5.159
    },
    {
      "text": "size is how many words do you want to",
      "start": 978.6,
      "duration": 4.799
    },
    {
      "text": "give as input for the model to be making",
      "start": 980.959,
      "duration": 4.721
    },
    {
      "text": "its prediction so here the context size",
      "start": 983.399,
      "duration": 5.12
    },
    {
      "text": "is equal to four right so if we give up",
      "start": 985.68,
      "duration": 4.8
    },
    {
      "text": "to four four words the model will be",
      "start": 988.519,
      "duration": 3.8
    },
    {
      "text": "able to predict the next",
      "start": 990.48,
      "duration": 4.359
    },
    {
      "text": "word that is what the context size",
      "start": 992.319,
      "duration": 4.64
    },
    {
      "text": "actually means so we want to create",
      "start": 994.839,
      "duration": 4.601
    },
    {
      "text": "input output arrays like this so let me",
      "start": 996.959,
      "duration": 5.68
    },
    {
      "text": "show you how those can be created for",
      "start": 999.44,
      "duration": 5.44
    },
    {
      "text": "this data set of the verdict which we",
      "start": 1002.639,
      "duration": 4.64
    },
    {
      "text": "have seen okay so first we have to",
      "start": 1004.88,
      "duration": 4.72
    },
    {
      "text": "determine the context size as I told you",
      "start": 1007.279,
      "duration": 4.201
    },
    {
      "text": "the context size determines how many",
      "start": 1009.6,
      "duration": 4.679
    },
    {
      "text": "tokens are included in the input so let",
      "start": 1011.48,
      "duration": 4.88
    },
    {
      "text": "me explain the context size a bit more",
      "start": 1014.279,
      "duration": 4.201
    },
    {
      "text": "here currently we are choosing context",
      "start": 1016.36,
      "duration": 4.399
    },
    {
      "text": "size of four you can choose anything",
      "start": 1018.48,
      "duration": 3.64
    },
    {
      "text": "which you want and you can play around",
      "start": 1020.759,
      "duration": 3.56
    },
    {
      "text": "with this code when I share it with you",
      "start": 1022.12,
      "duration": 4.76
    },
    {
      "text": "so the context size of four means that",
      "start": 1024.319,
      "duration": 4.6
    },
    {
      "text": "the model is trained to look at a",
      "start": 1026.88,
      "duration": 4.36
    },
    {
      "text": "sequence of four words or",
      "start": 1028.919,
      "duration": 4.961
    },
    {
      "text": "tokens to predict the next word in the",
      "start": 1031.24,
      "duration": 5.24
    },
    {
      "text": "sequence so the input X is the first",
      "start": 1033.88,
      "duration": 5.28
    },
    {
      "text": "four tokens let's say 1 2 3 4 and the",
      "start": 1036.48,
      "duration": 5.0
    },
    {
      "text": "target Y is the next four tokens which",
      "start": 1039.16,
      "duration": 6.0
    },
    {
      "text": "is 2 3 4 5 so that is meant by context",
      "start": 1041.48,
      "duration": 6.0
    },
    {
      "text": "size so the input if the input is 1 2 3",
      "start": 1045.16,
      "duration": 4.92
    },
    {
      "text": "4 the output is 2 3 4 5 what does it",
      "start": 1047.48,
      "duration": 5.8
    },
    {
      "text": "mean if the input is one the output will",
      "start": 1050.08,
      "duration": 5.8
    },
    {
      "text": "be two if the input is 1 two the output",
      "start": 1053.28,
      "duration": 5.36
    },
    {
      "text": "will be three if the input is 1 2 3 the",
      "start": 1055.88,
      "duration": 5.4
    },
    {
      "text": "output will be four if the input is 1 2",
      "start": 1058.64,
      "duration": 5.2
    },
    {
      "text": "3 4 the output will be five but the",
      "start": 1061.28,
      "duration": 5.36
    },
    {
      "text": "input cannot be one 2 3 4 5 because then",
      "start": 1063.84,
      "duration": 5.44
    },
    {
      "text": "the context size would be exceeded to",
      "start": 1066.64,
      "duration": 4.88
    },
    {
      "text": "think of it intuitively the context size",
      "start": 1069.28,
      "duration": 4.48
    },
    {
      "text": "is basically how many words the model",
      "start": 1071.52,
      "duration": 4.6
    },
    {
      "text": "should pay attention at one time to",
      "start": 1073.76,
      "duration": 5.96
    },
    {
      "text": "predict the next word so let's now take",
      "start": 1076.12,
      "duration": 5.439
    },
    {
      "text": "a simple thing so we have this encoded",
      "start": 1079.72,
      "duration": 4.4
    },
    {
      "text": "sample which contains the token IDs of",
      "start": 1081.559,
      "duration": 5.24
    },
    {
      "text": "the encoded data set what I will first",
      "start": 1084.12,
      "duration": 4.679
    },
    {
      "text": "do is that I will first take the four",
      "start": 1086.799,
      "duration": 3.88
    },
    {
      "text": "elements which are the first four",
      "start": 1088.799,
      "duration": 4.521
    },
    {
      "text": "elements that is my X which is the input",
      "start": 1090.679,
      "duration": 5.521
    },
    {
      "text": "and then I'll just shift this x Matrix X",
      "start": 1093.32,
      "duration": 5.719
    },
    {
      "text": "array by one and then that will be my Y",
      "start": 1096.2,
      "duration": 5.8
    },
    {
      "text": "which is the output so let's print out X",
      "start": 1099.039,
      "duration": 5.081
    },
    {
      "text": "so the IDS which are associated with the",
      "start": 1102.0,
      "duration": 7.039
    },
    {
      "text": "first four encoded samples are 290 4920",
      "start": 1104.12,
      "duration": 6.559
    },
    {
      "text": "2241 and",
      "start": 1109.039,
      "duration": 3.921
    },
    {
      "text": "287 and then the IDS which are",
      "start": 1110.679,
      "duration": 5.681
    },
    {
      "text": "associated with Y which is the output is",
      "start": 1112.96,
      "duration": 8.4
    },
    {
      "text": "4920 2241 287 and 257 what does this",
      "start": 1116.36,
      "duration": 8.16
    },
    {
      "text": "mean if the input ID is 290 then the",
      "start": 1121.36,
      "duration": 6.92
    },
    {
      "text": "output will be 4920 if the input is 290",
      "start": 1124.52,
      "duration": 6.48
    },
    {
      "text": "and 4920 the output is",
      "start": 1128.28,
      "duration": 7.56
    },
    {
      "text": "2241 if the input is 290 4920 and 2241",
      "start": 1131.0,
      "duration": 8.12
    },
    {
      "text": "the output will be 287 and if the input",
      "start": 1135.84,
      "duration": 7.36
    },
    {
      "text": "is 290 4920 2241 and 287 the output will",
      "start": 1139.12,
      "duration": 4.96
    },
    {
      "text": "be",
      "start": 1143.2,
      "duration": 4.2
    },
    {
      "text": "257 this is how the input output pairs",
      "start": 1144.08,
      "duration": 5.32
    },
    {
      "text": "are actually",
      "start": 1147.4,
      "duration": 5.12
    },
    {
      "text": "constructed so uh what we can do now is",
      "start": 1149.4,
      "duration": 5.08
    },
    {
      "text": "that processing the inputs along with",
      "start": 1152.52,
      "duration": 4.92
    },
    {
      "text": "the targets and remember the targets are",
      "start": 1154.48,
      "duration": 5.6
    },
    {
      "text": "just the input shifted by one position",
      "start": 1157.44,
      "duration": 4.359
    },
    {
      "text": "we can then create the next word",
      "start": 1160.08,
      "duration": 4.36
    },
    {
      "text": "prediction tasks as follows so what I",
      "start": 1161.799,
      "duration": 4.321
    },
    {
      "text": "just explained to you I've written this",
      "start": 1164.44,
      "duration": 5.76
    },
    {
      "text": "in code so I have created two uh",
      "start": 1166.12,
      "duration": 6.799
    },
    {
      "text": "variables here called context and",
      "start": 1170.2,
      "duration": 5.8
    },
    {
      "text": "desired and I'm looping in so the",
      "start": 1172.919,
      "duration": 5.401
    },
    {
      "text": "context size is four so this Loop will",
      "start": 1176.0,
      "duration": 5.84
    },
    {
      "text": "go from 1 to five so in the when I is",
      "start": 1178.32,
      "duration": 5.479
    },
    {
      "text": "equal to 1 which is the first iteration",
      "start": 1181.84,
      "duration": 4.52
    },
    {
      "text": "the context will be just the first token",
      "start": 1183.799,
      "duration": 5.76
    },
    {
      "text": "ID which is 290 and the desired will be",
      "start": 1186.36,
      "duration": 5.96
    },
    {
      "text": "the next token ID which is",
      "start": 1189.559,
      "duration": 6.24
    },
    {
      "text": "4920 awesome when I is equal to 2 then",
      "start": 1192.32,
      "duration": 5.96
    },
    {
      "text": "the context will be the first two tokens",
      "start": 1195.799,
      "duration": 5.841
    },
    {
      "text": "which is 290 and 4920 and the desired",
      "start": 1198.28,
      "duration": 6.08
    },
    {
      "text": "will be the next token which is",
      "start": 1201.64,
      "duration": 6.72
    },
    {
      "text": "2241 if I is equal to 3 uh then the",
      "start": 1204.36,
      "duration": 6.319
    },
    {
      "text": "context would be the first three token",
      "start": 1208.36,
      "duration": 6.6
    },
    {
      "text": "IDs which are 290 4920 and 2241 and the",
      "start": 1210.679,
      "duration": 6.36
    },
    {
      "text": "output will be or the desired will be",
      "start": 1214.96,
      "duration": 5.48
    },
    {
      "text": "the next token which is 287 and if I is",
      "start": 1217.039,
      "duration": 6.721
    },
    {
      "text": "equal to 4 then the context will be the",
      "start": 1220.44,
      "duration": 6.2
    },
    {
      "text": "first four tokens IDs and the desired",
      "start": 1223.76,
      "duration": 5.72
    },
    {
      "text": "will be the next which is 257",
      "start": 1226.64,
      "duration": 4.88
    },
    {
      "text": "so everything on the left of the arrow",
      "start": 1229.48,
      "duration": 4.4
    },
    {
      "text": "here refers to the input the large",
      "start": 1231.52,
      "duration": 5.279
    },
    {
      "text": "language model would receive uh and the",
      "start": 1233.88,
      "duration": 5.12
    },
    {
      "text": "token ID on the right hand side of the",
      "start": 1236.799,
      "duration": 5.041
    },
    {
      "text": "arrow represents the target token ID",
      "start": 1239.0,
      "duration": 5.2
    },
    {
      "text": "which the llm is supposed to",
      "start": 1241.84,
      "duration": 4.8
    },
    {
      "text": "predict so when we constructed these",
      "start": 1244.2,
      "duration": 4.359
    },
    {
      "text": "input output pairs this is what it",
      "start": 1246.64,
      "duration": 4.96
    },
    {
      "text": "actually means there are four prediction",
      "start": 1248.559,
      "duration": 5.961
    },
    {
      "text": "tasks here it's not one prediction task",
      "start": 1251.6,
      "duration": 5.16
    },
    {
      "text": "so when I created this input output pair",
      "start": 1254.52,
      "duration": 4.92
    },
    {
      "text": "of X and Y and even here here when I",
      "start": 1256.76,
      "duration": 4.56
    },
    {
      "text": "showed you the input output pair of X",
      "start": 1259.44,
      "duration": 4.56
    },
    {
      "text": "and Y it's not just one prediction task",
      "start": 1261.32,
      "duration": 4.44
    },
    {
      "text": "but there are four prediction tasks",
      "start": 1264.0,
      "duration": 3.72
    },
    {
      "text": "which are happening here and these are",
      "start": 1265.76,
      "duration": 4.399
    },
    {
      "text": "the four prediction tasks because the",
      "start": 1267.72,
      "duration": 4.36
    },
    {
      "text": "context size was four if the context",
      "start": 1270.159,
      "duration": 3.4
    },
    {
      "text": "size was eight there would have been",
      "start": 1272.08,
      "duration": 3.599
    },
    {
      "text": "eight prediction tasks in each input",
      "start": 1273.559,
      "duration": 4.72
    },
    {
      "text": "output pair so when you look at input",
      "start": 1275.679,
      "duration": 5.161
    },
    {
      "text": "output pairs usually regression and",
      "start": 1278.279,
      "duration": 4.88
    },
    {
      "text": "classification problem one input output",
      "start": 1280.84,
      "duration": 4.76
    },
    {
      "text": "pair corresponds to one prediction task",
      "start": 1283.159,
      "duration": 4.441
    },
    {
      "text": "image of a dog needs to be classified as",
      "start": 1285.6,
      "duration": 3.559
    },
    {
      "text": "whether it's a cat or a dog",
      "start": 1287.6,
      "duration": 4.6
    },
    {
      "text": "but in the case of llms one input output",
      "start": 1289.159,
      "duration": 4.961
    },
    {
      "text": "pair corresponds to the number of",
      "start": 1292.2,
      "duration": 5.24
    },
    {
      "text": "prediction tasks as set by the context",
      "start": 1294.12,
      "duration": 6.72
    },
    {
      "text": "size that is very important now what I'm",
      "start": 1297.44,
      "duration": 4.92
    },
    {
      "text": "going to do is that I'm going to take",
      "start": 1300.84,
      "duration": 3.88
    },
    {
      "text": "this simple the same code but I'm going",
      "start": 1302.36,
      "duration": 5.52
    },
    {
      "text": "to decode it into text so that you can",
      "start": 1304.72,
      "duration": 5.079
    },
    {
      "text": "get a feel of what is exactly happening",
      "start": 1307.88,
      "duration": 3.84
    },
    {
      "text": "here so here you can see I've taken the",
      "start": 1309.799,
      "duration": 4.88
    },
    {
      "text": "same code but I'm printing the decoded",
      "start": 1311.72,
      "duration": 5.04
    },
    {
      "text": "context and I'm printing the decoded",
      "start": 1314.679,
      "duration": 5.161
    },
    {
      "text": "desired value so if and is the input",
      "start": 1316.76,
      "duration": 5.12
    },
    {
      "text": "established is the output if and",
      "start": 1319.84,
      "duration": 4.04
    },
    {
      "text": "established is the input himself is the",
      "start": 1321.88,
      "duration": 4.64
    },
    {
      "text": "output if and established himself is the",
      "start": 1323.88,
      "duration": 4.52
    },
    {
      "text": "output the next word which is in is the",
      "start": 1326.52,
      "duration": 4.639
    },
    {
      "text": "output and if and established himself in",
      "start": 1328.4,
      "duration": 4.92
    },
    {
      "text": "is the input then the next word uh that",
      "start": 1331.159,
      "duration": 5.161
    },
    {
      "text": "is the output now this is exactly what",
      "start": 1333.32,
      "duration": 4.599
    },
    {
      "text": "we started the lecture with right you",
      "start": 1336.32,
      "duration": 3.359
    },
    {
      "text": "remember we started the lecture with",
      "start": 1337.919,
      "duration": 5.201
    },
    {
      "text": "this and uh now what we have done is",
      "start": 1339.679,
      "duration": 5.401
    },
    {
      "text": "that through code we have just created",
      "start": 1343.12,
      "duration": 4.96
    },
    {
      "text": "very simple input output pairs X and Y",
      "start": 1345.08,
      "duration": 4.8
    },
    {
      "text": "and we have seen how these pairs can be",
      "start": 1348.08,
      "duration": 5.56
    },
    {
      "text": "used to create the input and the output",
      "start": 1349.88,
      "duration": 6.279
    },
    {
      "text": "awesome right so this is just the first",
      "start": 1353.64,
      "duration": 5.72
    },
    {
      "text": "step of what we need to be doing what we",
      "start": 1356.159,
      "duration": 5.201
    },
    {
      "text": "have done so far is we have created the",
      "start": 1359.36,
      "duration": 5.24
    },
    {
      "text": "input output pairs that we can turn into",
      "start": 1361.36,
      "duration": 5.679
    },
    {
      "text": "use for the llm training so later we are",
      "start": 1364.6,
      "duration": 4.24
    },
    {
      "text": "going to do llm training and so we have",
      "start": 1367.039,
      "duration": 4.24
    },
    {
      "text": "created input output pairs now but we",
      "start": 1368.84,
      "duration": 4.0
    },
    {
      "text": "need to create them in a much more",
      "start": 1371.279,
      "duration": 3.801
    },
    {
      "text": "structured manner we need to create them",
      "start": 1372.84,
      "duration": 4.92
    },
    {
      "text": "for the entire data set not just that",
      "start": 1375.08,
      "duration": 5.8
    },
    {
      "text": "later we will parallel processing so if",
      "start": 1377.76,
      "duration": 5.159
    },
    {
      "text": "we have multiple CPUs and we need to do",
      "start": 1380.88,
      "duration": 3.96
    },
    {
      "text": "parallel Computing we need to do",
      "start": 1382.919,
      "duration": 3.481
    },
    {
      "text": "Computing in",
      "start": 1384.84,
      "duration": 5.0
    },
    {
      "text": "batches so we are going to do this in a",
      "start": 1386.4,
      "duration": 6.04
    },
    {
      "text": "very structured Manner and for that what",
      "start": 1389.84,
      "duration": 4.439
    },
    {
      "text": "we are going to be doing is we are going",
      "start": 1392.44,
      "duration": 5.08
    },
    {
      "text": "to use something called as uh data",
      "start": 1394.279,
      "duration": 5.841
    },
    {
      "text": "loader so now there is only one more",
      "start": 1397.52,
      "duration": 4.56
    },
    {
      "text": "task which is remaining before we can",
      "start": 1400.12,
      "duration": 3.48
    },
    {
      "text": "look at the vector embeddings in the",
      "start": 1402.08,
      "duration": 4.4
    },
    {
      "text": "next lecture and that is implementing an",
      "start": 1403.6,
      "duration": 6.079
    },
    {
      "text": "efficient data loader",
      "start": 1406.48,
      "duration": 5.84
    },
    {
      "text": "uh that iterates over the input data set",
      "start": 1409.679,
      "duration": 5.081
    },
    {
      "text": "and Returns the inputs and targets as P",
      "start": 1412.32,
      "duration": 3.32
    },
    {
      "text": "torch",
      "start": 1414.76,
      "duration": 3.159
    },
    {
      "text": "tensors So currently we have got the",
      "start": 1415.64,
      "duration": 4.12
    },
    {
      "text": "input output arrays right but they are",
      "start": 1417.919,
      "duration": 4.36
    },
    {
      "text": "not tensors why do we need tensors",
      "start": 1419.76,
      "duration": 4.56
    },
    {
      "text": "because all the optimization procedures",
      "start": 1422.279,
      "duration": 4.561
    },
    {
      "text": "which come later we we are going to use",
      "start": 1424.32,
      "duration": 5.92
    },
    {
      "text": "py torch and py torch works with tensors",
      "start": 1426.84,
      "duration": 5.24
    },
    {
      "text": "so we need input tensors and we need",
      "start": 1430.24,
      "duration": 4.12
    },
    {
      "text": "output tensors no need to worry if you",
      "start": 1432.08,
      "duration": 4.04
    },
    {
      "text": "don't know what a tensor is you can just",
      "start": 1434.36,
      "duration": 3.679
    },
    {
      "text": "think of it as a two-dimensional array",
      "start": 1436.12,
      "duration": 4.439
    },
    {
      "text": "for now or multi-dimensional array no",
      "start": 1438.039,
      "duration": 4.801
    },
    {
      "text": "need to worry about this this will not",
      "start": 1440.559,
      "duration": 4.401
    },
    {
      "text": "stop you from understanding this",
      "start": 1442.84,
      "duration": 5.04
    },
    {
      "text": "lecture so our goal is this we want to",
      "start": 1444.96,
      "duration": 4.8
    },
    {
      "text": "implement a data loader which creates",
      "start": 1447.88,
      "duration": 4.72
    },
    {
      "text": "two tensors an input tensor which",
      "start": 1449.76,
      "duration": 5.56
    },
    {
      "text": "contains the text that the llm sees and",
      "start": 1452.6,
      "duration": 5.28
    },
    {
      "text": "the target tensor that includes the",
      "start": 1455.32,
      "duration": 4.56
    },
    {
      "text": "targets for the llms to predict that's",
      "start": 1457.88,
      "duration": 4.039
    },
    {
      "text": "it basically we have to create something",
      "start": 1459.88,
      "duration": 3.679
    },
    {
      "text": "exactly like what I showed you in the",
      "start": 1461.919,
      "duration": 3.921
    },
    {
      "text": "code before but we need to create it in",
      "start": 1463.559,
      "duration": 4.6
    },
    {
      "text": "a tensor format and we need to do it in",
      "start": 1465.84,
      "duration": 4.839
    },
    {
      "text": "a structured manner so that's why we are",
      "start": 1468.159,
      "duration": 5.561
    },
    {
      "text": "going to use something called as data",
      "start": 1470.679,
      "duration": 5.761
    },
    {
      "text": "set and data loader so the these are",
      "start": 1473.72,
      "duration": 4.8
    },
    {
      "text": "data sets and data loaders which are in",
      "start": 1476.44,
      "duration": 3.92
    },
    {
      "text": "Python and here you can just see some",
      "start": 1478.52,
      "duration": 3.92
    },
    {
      "text": "examples which have been done for some",
      "start": 1480.36,
      "duration": 4.199
    },
    {
      "text": "classification data sets but essentially",
      "start": 1482.44,
      "duration": 5.32
    },
    {
      "text": "data sets and data loaders enable you to",
      "start": 1484.559,
      "duration": 5.6
    },
    {
      "text": "load or process the data in a much more",
      "start": 1487.76,
      "duration": 4.6
    },
    {
      "text": "efficient and compact manner as we'll",
      "start": 1490.159,
      "duration": 3.561
    },
    {
      "text": "see right",
      "start": 1492.36,
      "duration": 4.319
    },
    {
      "text": "now awesome so now what we are going to",
      "start": 1493.72,
      "duration": 4.76
    },
    {
      "text": "do in the next step is we are going to",
      "start": 1496.679,
      "duration": 5.521
    },
    {
      "text": "Implement a data loader and uh for the",
      "start": 1498.48,
      "duration": 5.72
    },
    {
      "text": "efficient data loader implementation we",
      "start": 1502.2,
      "duration": 5.44
    },
    {
      "text": "will use the pytorch inbuilt data set",
      "start": 1504.2,
      "duration": 6.04
    },
    {
      "text": "and data loader classes so these are the",
      "start": 1507.64,
      "duration": 4.88
    },
    {
      "text": "data set and data loader classes link",
      "start": 1510.24,
      "duration": 4.28
    },
    {
      "text": "which I've shown right now I'll also",
      "start": 1512.52,
      "duration": 4.759
    },
    {
      "text": "attach the link in the video",
      "start": 1514.52,
      "duration": 5.039
    },
    {
      "text": "description before going into the code",
      "start": 1517.279,
      "duration": 4.561
    },
    {
      "text": "further I just want to show you what we",
      "start": 1519.559,
      "duration": 4.681
    },
    {
      "text": "expect the data loader to do so that you",
      "start": 1521.84,
      "duration": 4.76
    },
    {
      "text": "have a visual understanding I have seen",
      "start": 1524.24,
      "duration": 3.88
    },
    {
      "text": "that until you get a visual",
      "start": 1526.6,
      "duration": 2.84
    },
    {
      "text": "understanding sending the code becomes",
      "start": 1528.12,
      "duration": 3.679
    },
    {
      "text": "very difficult to really Master but if",
      "start": 1529.44,
      "duration": 4.119
    },
    {
      "text": "you know what you want to implement it's",
      "start": 1531.799,
      "duration": 4.161
    },
    {
      "text": "really very easy so in this section what",
      "start": 1533.559,
      "duration": 4.521
    },
    {
      "text": "are we doing we are implementing a data",
      "start": 1535.96,
      "duration": 4.599
    },
    {
      "text": "loader that fetches the input output",
      "start": 1538.08,
      "duration": 4.44
    },
    {
      "text": "Target pairs using a sliding window",
      "start": 1540.559,
      "duration": 6.881
    },
    {
      "text": "approach let's see what this means so uh",
      "start": 1542.52,
      "duration": 7.759
    },
    {
      "text": "here so what we are going to do is that",
      "start": 1547.44,
      "duration": 5.52
    },
    {
      "text": "let's look at this sample text in the",
      "start": 1550.279,
      "duration": 5.321
    },
    {
      "text": "Heart of the City stood the old library",
      "start": 1552.96,
      "duration": 5.56
    },
    {
      "text": "A Relic from a Bagon era let's say this",
      "start": 1555.6,
      "duration": 5.24
    },
    {
      "text": "is the kind of sentence and we want to",
      "start": 1558.52,
      "duration": 4.879
    },
    {
      "text": "create input output Pairs and we are",
      "start": 1560.84,
      "duration": 4.4
    },
    {
      "text": "going to create input output pairs with",
      "start": 1563.399,
      "duration": 6.241
    },
    {
      "text": "a context size of four okay so let's say",
      "start": 1565.24,
      "duration": 8.08
    },
    {
      "text": "if the input is in the heart of let's",
      "start": 1569.64,
      "duration": 7.08
    },
    {
      "text": "say the input is in the heart of the",
      "start": 1573.32,
      "duration": 5.599
    },
    {
      "text": "output tensor will be shifted by one",
      "start": 1576.72,
      "duration": 4.439
    },
    {
      "text": "right as we already saw so the output",
      "start": 1578.919,
      "duration": 7.161
    },
    {
      "text": "will be the heart of the correct so the",
      "start": 1581.159,
      "duration": 7.481
    },
    {
      "text": "first input pair is in the heart of and",
      "start": 1586.08,
      "duration": 5.24
    },
    {
      "text": "the first output is the heart of the now",
      "start": 1588.64,
      "duration": 4.72
    },
    {
      "text": "in this input output pair there will be",
      "start": 1591.32,
      "duration": 5.32
    },
    {
      "text": "four prediction tasks the first is that",
      "start": 1593.36,
      "duration": 5.48
    },
    {
      "text": "if the input is in the prediction should",
      "start": 1596.64,
      "duration": 5.56
    },
    {
      "text": "be the if the input is in the the",
      "start": 1598.84,
      "duration": 5.839
    },
    {
      "text": "prediction should be heart uh let me",
      "start": 1602.2,
      "duration": 4.719
    },
    {
      "text": "switch to a different",
      "start": 1604.679,
      "duration": 5.6
    },
    {
      "text": "color if the input is in the heart the",
      "start": 1606.919,
      "duration": 5.601
    },
    {
      "text": "prediction should be off and if the",
      "start": 1610.279,
      "duration": 4.561
    },
    {
      "text": "input is in the heart of the prediction",
      "start": 1612.52,
      "duration": 6.96
    },
    {
      "text": "should be the so uh first of all we have",
      "start": 1614.84,
      "duration": 7.28
    },
    {
      "text": "an X which is the input tensor and Y",
      "start": 1619.48,
      "duration": 5.919
    },
    {
      "text": "which is the output tensor now let's see",
      "start": 1622.12,
      "duration": 6.559
    },
    {
      "text": "what the row of every tensor are",
      "start": 1625.399,
      "duration": 5.681
    },
    {
      "text": "representing uh so we collect the inputs",
      "start": 1628.679,
      "duration": 3.88
    },
    {
      "text": "in a tensor",
      "start": 1631.08,
      "duration": 5.64
    },
    {
      "text": "X so we collect the inputs in a tensor X",
      "start": 1632.559,
      "duration": 6.521
    },
    {
      "text": "where each row represents one input",
      "start": 1636.72,
      "duration": 5.0
    },
    {
      "text": "context so let's look at the tensor X if",
      "start": 1639.08,
      "duration": 5.52
    },
    {
      "text": "you see each row each row of this is one",
      "start": 1641.72,
      "duration": 6.04
    },
    {
      "text": "input context in the Heart of the City",
      "start": 1644.6,
      "duration": 7.079
    },
    {
      "text": "stood the so each row represents one uh",
      "start": 1647.76,
      "duration": 6.96
    },
    {
      "text": "input context so the first input output",
      "start": 1651.679,
      "duration": 5.201
    },
    {
      "text": "pair will be in the heart of and the",
      "start": 1654.72,
      "duration": 4.52
    },
    {
      "text": "first output will be the heart of Thee",
      "start": 1656.88,
      "duration": 4.679
    },
    {
      "text": "the second input will be the CT stood",
      "start": 1659.24,
      "duration": 4.919
    },
    {
      "text": "the and the second output will be CT",
      "start": 1661.559,
      "duration": 5.881
    },
    {
      "text": "stood the old so basically what I",
      "start": 1664.159,
      "duration": 5.041
    },
    {
      "text": "earlier in this lecture I showed you one",
      "start": 1667.44,
      "duration": 4.079
    },
    {
      "text": "input output pair when we look at",
      "start": 1669.2,
      "duration": 5.04
    },
    {
      "text": "tensors if you look at each row each row",
      "start": 1671.519,
      "duration": 5.28
    },
    {
      "text": "of the X tensor is an input each row of",
      "start": 1674.24,
      "duration": 5.48
    },
    {
      "text": "the Y tensor is the Corr oning output so",
      "start": 1676.799,
      "duration": 5.841
    },
    {
      "text": "the 50th row of the X X tensor and the",
      "start": 1679.72,
      "duration": 4.76
    },
    {
      "text": "50th row of the Y tensor will be the",
      "start": 1682.64,
      "duration": 3.6
    },
    {
      "text": "50th input output",
      "start": 1684.48,
      "duration": 4.799
    },
    {
      "text": "pair and in each input output pair there",
      "start": 1686.24,
      "duration": 5.84
    },
    {
      "text": "are four prediction tasks here as I as I",
      "start": 1689.279,
      "duration": 4.361
    },
    {
      "text": "told you because the context size is",
      "start": 1692.08,
      "duration": 3.719
    },
    {
      "text": "equal to four so essentially we are",
      "start": 1693.64,
      "duration": 3.68
    },
    {
      "text": "doing the same thing what we did in the",
      "start": 1695.799,
      "duration": 3.6
    },
    {
      "text": "earlier part of the lecture but we just",
      "start": 1697.32,
      "duration": 4.92
    },
    {
      "text": "take the entire text uh we put it in",
      "start": 1699.399,
      "duration": 5.321
    },
    {
      "text": "tensors in the rows of the tensor so we",
      "start": 1702.24,
      "duration": 4.76
    },
    {
      "text": "split the text into four words so the",
      "start": 1704.72,
      "duration": 4.319
    },
    {
      "text": "first four words are the first row the",
      "start": 1707.0,
      "duration": 4.12
    },
    {
      "text": "second four words are the second row and",
      "start": 1709.039,
      "duration": 4.201
    },
    {
      "text": "if you look at the output tensor it just",
      "start": 1711.12,
      "duration": 4.2
    },
    {
      "text": "the input tensor shifted by one that's",
      "start": 1713.24,
      "duration": 4.439
    },
    {
      "text": "it if you look at each row of the output",
      "start": 1715.32,
      "duration": 4.32
    },
    {
      "text": "tensor it's just the input tensor row",
      "start": 1717.679,
      "duration": 3.24
    },
    {
      "text": "shifted by",
      "start": 1719.64,
      "duration": 5.279
    },
    {
      "text": "one so the second tensor y uh the second",
      "start": 1720.919,
      "duration": 6.081
    },
    {
      "text": "tensor y contains the corresponding",
      "start": 1724.919,
      "duration": 4.521
    },
    {
      "text": "prediction targets next Words which are",
      "start": 1727.0,
      "duration": 4.76
    },
    {
      "text": "created by Shifting the input by one",
      "start": 1729.44,
      "duration": 4.68
    },
    {
      "text": "position this is very important for",
      "start": 1731.76,
      "duration": 4.919
    },
    {
      "text": "everyone who is watching this lecture to",
      "start": 1734.12,
      "duration": 5.88
    },
    {
      "text": "understand uh it all we are doing is",
      "start": 1736.679,
      "duration": 5.88
    },
    {
      "text": "next word prediction task so let me",
      "start": 1740.0,
      "duration": 5.6
    },
    {
      "text": "again explain this so that I I really",
      "start": 1742.559,
      "duration": 5.521
    },
    {
      "text": "want this concept to be understood",
      "start": 1745.6,
      "duration": 3.88
    },
    {
      "text": "because it's the heart of everything",
      "start": 1748.08,
      "duration": 3.079
    },
    {
      "text": "which we are going to do but let's look",
      "start": 1749.48,
      "duration": 4.319
    },
    {
      "text": "at the second row in the second row",
      "start": 1751.159,
      "duration": 4.681
    },
    {
      "text": "there will be four prediction tasks the",
      "start": 1753.799,
      "duration": 3.921
    },
    {
      "text": "first prediction task is when the input",
      "start": 1755.84,
      "duration": 4.92
    },
    {
      "text": "is the the output is City when the input",
      "start": 1757.72,
      "duration": 6.12
    },
    {
      "text": "is the city the output is stood when the",
      "start": 1760.76,
      "duration": 5.519
    },
    {
      "text": "input is the city stood the output is",
      "start": 1763.84,
      "duration": 4.76
    },
    {
      "text": "the and when the input is the city is",
      "start": 1766.279,
      "duration": 4.921
    },
    {
      "text": "stood the the output is the old the",
      "start": 1768.6,
      "duration": 5.12
    },
    {
      "text": "output is old so",
      "start": 1771.2,
      "duration": 5.24
    },
    {
      "text": "basically each input output pair",
      "start": 1773.72,
      "duration": 4.839
    },
    {
      "text": "corresponds to one prediction task and",
      "start": 1776.44,
      "duration": 4.52
    },
    {
      "text": "corresponds to four prediction tasks and",
      "start": 1778.559,
      "duration": 4.441
    },
    {
      "text": "we are just predicting the next word",
      "start": 1780.96,
      "duration": 4.599
    },
    {
      "text": "that's it it's as simple as that and",
      "start": 1783.0,
      "duration": 4.64
    },
    {
      "text": "that is exactly all we are actually",
      "start": 1785.559,
      "duration": 5.041
    },
    {
      "text": "doing in the code also so now I'm",
      "start": 1787.64,
      "duration": 7.08
    },
    {
      "text": "returning back to the code and uh This",
      "start": 1790.6,
      "duration": 6.12
    },
    {
      "text": "what I showed you here right now on the",
      "start": 1794.72,
      "duration": 3.52
    },
    {
      "text": "Whiteboard",
      "start": 1796.72,
      "duration": 3.559
    },
    {
      "text": "uh creating such kind of input tensor",
      "start": 1798.24,
      "duration": 3.919
    },
    {
      "text": "and output tensor is exactly what we are",
      "start": 1800.279,
      "duration": 4.12
    },
    {
      "text": "going to do in the code so if you if you",
      "start": 1802.159,
      "duration": 3.88
    },
    {
      "text": "have understood this the code will be",
      "start": 1804.399,
      "duration": 4.321
    },
    {
      "text": "much easier to understand so we are",
      "start": 1806.039,
      "duration": 4.441
    },
    {
      "text": "going to implement a data loader which",
      "start": 1808.72,
      "duration": 3.88
    },
    {
      "text": "creates these input and the output",
      "start": 1810.48,
      "duration": 4.439
    },
    {
      "text": "tensors and this will be done in four",
      "start": 1812.6,
      "duration": 4.84
    },
    {
      "text": "steps the first is tokenizing the entire",
      "start": 1814.919,
      "duration": 5.321
    },
    {
      "text": "text because uh we are going to deal",
      "start": 1817.44,
      "duration": 5.239
    },
    {
      "text": "with token IDs right now I'm showing you",
      "start": 1820.24,
      "duration": 4.439
    },
    {
      "text": "words over here but actually we'll deal",
      "start": 1822.679,
      "duration": 4.0
    },
    {
      "text": "with token IDs so we need the encoded",
      "start": 1824.679,
      "duration": 3.521
    },
    {
      "text": "text",
      "start": 1826.679,
      "duration": 3.88
    },
    {
      "text": "uh then we'll use a sliding window and",
      "start": 1828.2,
      "duration": 4.04
    },
    {
      "text": "now do you understand why is it called",
      "start": 1830.559,
      "duration": 2.72
    },
    {
      "text": "sliding",
      "start": 1832.24,
      "duration": 4.84
    },
    {
      "text": "window because uh look at this blue look",
      "start": 1833.279,
      "duration": 7.081
    },
    {
      "text": "at the blue window and the red window",
      "start": 1837.08,
      "duration": 6.16
    },
    {
      "text": "here so the blue is the input and then",
      "start": 1840.36,
      "duration": 6.08
    },
    {
      "text": "you slide it by one row slide it by one",
      "start": 1843.24,
      "duration": 5.64
    },
    {
      "text": "world and that's the output so each",
      "start": 1846.44,
      "duration": 4.92
    },
    {
      "text": "input and output pair is just sliding so",
      "start": 1848.88,
      "duration": 4.96
    },
    {
      "text": "you slide the input and then you get the",
      "start": 1851.36,
      "duration": 4.52
    },
    {
      "text": "output",
      "start": 1853.84,
      "duration": 4.959
    },
    {
      "text": "pair uh and then finally what we'll be",
      "start": 1855.88,
      "duration": 4.56
    },
    {
      "text": "doing is that we'll return the total",
      "start": 1858.799,
      "duration": 3.76
    },
    {
      "text": "number of rows in the data set and we'll",
      "start": 1860.44,
      "duration": 4.04
    },
    {
      "text": "return a single Row from the data set",
      "start": 1862.559,
      "duration": 5.401
    },
    {
      "text": "I'll show what this means so here we are",
      "start": 1864.48,
      "duration": 6.84
    },
    {
      "text": "going to define a class um and this",
      "start": 1867.96,
      "duration": 7.64
    },
    {
      "text": "class is going to take a data set now uh",
      "start": 1871.32,
      "duration": 6.52
    },
    {
      "text": "for this what we are doing is from tor.",
      "start": 1875.6,
      "duration": 4.4
    },
    {
      "text": "utils we are importing data set and data",
      "start": 1877.84,
      "duration": 4.88
    },
    {
      "text": "loader the data loader will come a later",
      "start": 1880.0,
      "duration": 5.039
    },
    {
      "text": "right now we have our goal is to define",
      "start": 1882.72,
      "duration": 4.959
    },
    {
      "text": "the data set and the data set cannot",
      "start": 1885.039,
      "duration": 5.961
    },
    {
      "text": "just be a bunch of tokens we need to",
      "start": 1887.679,
      "duration": 5.12
    },
    {
      "text": "make sure the data set is in input",
      "start": 1891.0,
      "duration": 5.039
    },
    {
      "text": "output pairs so what do we do here first",
      "start": 1892.799,
      "duration": 5.0
    },
    {
      "text": "we see what are the arguments which are",
      "start": 1896.039,
      "duration": 3.561
    },
    {
      "text": "taken when we create an instance of this",
      "start": 1897.799,
      "duration": 4.041
    },
    {
      "text": "class so when we create an instance of",
      "start": 1899.6,
      "duration": 4.079
    },
    {
      "text": "this class we basically need to specify",
      "start": 1901.84,
      "duration": 4.719
    },
    {
      "text": "four things we need to specify all the",
      "start": 1903.679,
      "duration": 4.641
    },
    {
      "text": "text file which we have so this is the",
      "start": 1906.559,
      "duration": 5.0
    },
    {
      "text": "data set the txt file then we need to",
      "start": 1908.32,
      "duration": 5.28
    },
    {
      "text": "specify the tokenizer so here we are",
      "start": 1911.559,
      "duration": 4.48
    },
    {
      "text": "using the bite pair tokenizer then we",
      "start": 1913.6,
      "duration": 4.679
    },
    {
      "text": "need to specify the max length the max",
      "start": 1916.039,
      "duration": 4.801
    },
    {
      "text": "length is the context size here we are",
      "start": 1918.279,
      "duration": 4.561
    },
    {
      "text": "going to use a context size or context",
      "start": 1920.84,
      "duration": 3.799
    },
    {
      "text": "length of four and then there is",
      "start": 1922.84,
      "duration": 4.24
    },
    {
      "text": "something called as stride so what",
      "start": 1924.639,
      "duration": 4.361
    },
    {
      "text": "stride means we'll come come to that in",
      "start": 1927.08,
      "duration": 4.12
    },
    {
      "text": "a moment but right now just know that",
      "start": 1929.0,
      "duration": 3.72
    },
    {
      "text": "there are four arguments which this",
      "start": 1931.2,
      "duration": 3.959
    },
    {
      "text": "class actually takes now what we'll be",
      "start": 1932.72,
      "duration": 4.0
    },
    {
      "text": "doing is that we'll be creating two",
      "start": 1935.159,
      "duration": 4.561
    },
    {
      "text": "arrays the first is called input IDs the",
      "start": 1936.72,
      "duration": 5.559
    },
    {
      "text": "second is called Target IDs what we'll",
      "start": 1939.72,
      "duration": 6.28
    },
    {
      "text": "be doing is that in input IDs uh we are",
      "start": 1942.279,
      "duration": 6.36
    },
    {
      "text": "so here you see we are going",
      "start": 1946.0,
      "duration": 6.88
    },
    {
      "text": "to uh loop over the entire data set so",
      "start": 1948.639,
      "duration": 6.841
    },
    {
      "text": "when I is equal to 1 the input ID the",
      "start": 1952.88,
      "duration": 5.159
    },
    {
      "text": "input chunk will have token IDs which",
      "start": 1955.48,
      "duration": 5.679
    },
    {
      "text": "are from 0 to 4 and the target will be",
      "start": 1958.039,
      "duration": 6.081
    },
    {
      "text": "token IDs from 1 to five which is just",
      "start": 1961.159,
      "duration": 5.24
    },
    {
      "text": "shifted by one and then you append this",
      "start": 1964.12,
      "duration": 5.559
    },
    {
      "text": "to the input ID's tensor and the target",
      "start": 1966.399,
      "duration": 6.041
    },
    {
      "text": "ID's tensor so when I is equal to one",
      "start": 1969.679,
      "duration": 4.641
    },
    {
      "text": "what will be appended is the first row",
      "start": 1972.44,
      "duration": 4.719
    },
    {
      "text": "of the input and the first row of the",
      "start": 1974.32,
      "duration": 4.52
    },
    {
      "text": "output",
      "start": 1977.159,
      "duration": 6.281
    },
    {
      "text": "so let me actually rub rub erase this a",
      "start": 1978.84,
      "duration": 7.079
    },
    {
      "text": "bit okay so in the code we saw the",
      "start": 1983.44,
      "duration": 4.64
    },
    {
      "text": "iterations right so when I is equal to 1",
      "start": 1985.919,
      "duration": 4.041
    },
    {
      "text": "the first row will be appended to the",
      "start": 1988.08,
      "duration": 4.36
    },
    {
      "text": "input tensor and the first row will be",
      "start": 1989.96,
      "duration": 5.12
    },
    {
      "text": "appended to the output tensor so if you",
      "start": 1992.44,
      "duration": 6.64
    },
    {
      "text": "see the input ID is is the input tensor",
      "start": 1995.08,
      "duration": 6.079
    },
    {
      "text": "and this input chunk is being appended",
      "start": 1999.08,
      "duration": 4.839
    },
    {
      "text": "that's the first row now when I is equal",
      "start": 2001.159,
      "duration": 6.0
    },
    {
      "text": "to 1 we slide over to the next so if I",
      "start": 2003.919,
      "duration": 6.161
    },
    {
      "text": "is equal to one we uh we we look at the",
      "start": 2007.159,
      "duration": 6.561
    },
    {
      "text": "next chunk so the first chunk will",
      "start": 2010.08,
      "duration": 6.719
    },
    {
      "text": "be in the heart of in the heart of the",
      "start": 2013.72,
      "duration": 5.48
    },
    {
      "text": "second chunk here is the city stood the",
      "start": 2016.799,
      "duration": 4.441
    },
    {
      "text": "that's the third chunk the fourth chunk",
      "start": 2019.2,
      "duration": 6.319
    },
    {
      "text": "is old library a so we are going to",
      "start": 2021.24,
      "duration": 6.6
    },
    {
      "text": "divide the entire data set into chunks",
      "start": 2025.519,
      "duration": 3.601
    },
    {
      "text": "like this and then we are going to",
      "start": 2027.84,
      "duration": 4.0
    },
    {
      "text": "append that to the input tensor and just",
      "start": 2029.12,
      "duration": 5.039
    },
    {
      "text": "we are going to slide the chunk by one",
      "start": 2031.84,
      "duration": 4.04
    },
    {
      "text": "and then that we are going to up to the",
      "start": 2034.159,
      "duration": 3.921
    },
    {
      "text": "output tensor this is how we are",
      "start": 2035.88,
      "duration": 4.519
    },
    {
      "text": "creating the input and the output",
      "start": 2038.08,
      "duration": 5.479
    },
    {
      "text": "tensors and then we are going to Loop",
      "start": 2040.399,
      "duration": 5.801
    },
    {
      "text": "till we reach the end of the data set so",
      "start": 2043.559,
      "duration": 6.641
    },
    {
      "text": "length of data set minus the max length",
      "start": 2046.2,
      "duration": 6.199
    },
    {
      "text": "why minus max length because the last",
      "start": 2050.2,
      "duration": 5.12
    },
    {
      "text": "thing will include the context size and",
      "start": 2052.399,
      "duration": 5.081
    },
    {
      "text": "so we don't want to spill over the data",
      "start": 2055.32,
      "duration": 4.88
    },
    {
      "text": "set essentially if you are finding this",
      "start": 2057.48,
      "duration": 4.52
    },
    {
      "text": "section a bit hard to understand just",
      "start": 2060.2,
      "duration": 3.679
    },
    {
      "text": "remember that all we are doing here is",
      "start": 2062.0,
      "duration": 4.679
    },
    {
      "text": "that we have a data set we are chunking",
      "start": 2063.879,
      "duration": 5.601
    },
    {
      "text": "the data set so we have in first we have",
      "start": 2066.679,
      "duration": 5.0
    },
    {
      "text": "the input chunk and then we have the",
      "start": 2069.48,
      "duration": 4.52
    },
    {
      "text": "output chunk actually I think let me",
      "start": 2071.679,
      "duration": 6.081
    },
    {
      "text": "explain this using a Hands-On example",
      "start": 2074.0,
      "duration": 5.359
    },
    {
      "text": "over here so let's take this this",
      "start": 2077.76,
      "duration": 3.96
    },
    {
      "text": "example itself which I have written here",
      "start": 2079.359,
      "duration": 4.641
    },
    {
      "text": "right now uh what we are essentially",
      "start": 2081.72,
      "duration": 4.119
    },
    {
      "text": "doing here is that we are first going to",
      "start": 2084.0,
      "duration": 4.52
    },
    {
      "text": "have an input chunk so two Implement",
      "start": 2085.839,
      "duration": 4.76
    },
    {
      "text": "efficient data loaders that's my first",
      "start": 2088.52,
      "duration": 4.92
    },
    {
      "text": "input chunk then what I'm going to do",
      "start": 2090.599,
      "duration": 5.921
    },
    {
      "text": "then I'm going to shift it by right",
      "start": 2093.44,
      "duration": 4.84
    },
    {
      "text": "shift it to the right by one and then",
      "start": 2096.52,
      "duration": 4.04
    },
    {
      "text": "I'll have my output chunk so the output",
      "start": 2098.28,
      "duration": 4.12
    },
    {
      "text": "chunk is Implement efficient data",
      "start": 2100.56,
      "duration": 4.76
    },
    {
      "text": "loaders V so that's my first input",
      "start": 2102.4,
      "duration": 5.04
    },
    {
      "text": "output chunk so the input chunk will be",
      "start": 2105.32,
      "duration": 3.88
    },
    {
      "text": "the first row of the tensor the output",
      "start": 2107.44,
      "duration": 3.12
    },
    {
      "text": "chunk will be the second row of my",
      "start": 2109.2,
      "duration": 4.159
    },
    {
      "text": "tensor and then I'll slide so the way",
      "start": 2110.56,
      "duration": 5.2
    },
    {
      "text": "I'll slide will depend on my stride so",
      "start": 2113.359,
      "duration": 6.401
    },
    {
      "text": "if my stride is equal to let's say one",
      "start": 2115.76,
      "duration": 6.24
    },
    {
      "text": "it means that my next input will be",
      "start": 2119.76,
      "duration": 4.88
    },
    {
      "text": "Implement efficient data loaders and my",
      "start": 2122.0,
      "duration": 5.359
    },
    {
      "text": "next output will be sorry my next input",
      "start": 2124.64,
      "duration": 4.76
    },
    {
      "text": "will be Implement efficient data loaders",
      "start": 2127.359,
      "duration": 4.801
    },
    {
      "text": "V and my next output would be efficient",
      "start": 2129.4,
      "duration": 5.88
    },
    {
      "text": "data loaders V collect so at each time",
      "start": 2132.16,
      "duration": 5.24
    },
    {
      "text": "the output is just the input shifted by",
      "start": 2135.28,
      "duration": 4.559
    },
    {
      "text": "one and stride determines how much we",
      "start": 2137.4,
      "duration": 5.199
    },
    {
      "text": "slide so in the example which we took",
      "start": 2139.839,
      "duration": 5.28
    },
    {
      "text": "here if you see the in the first input",
      "start": 2142.599,
      "duration": 5.121
    },
    {
      "text": "is in the heart of but the second input",
      "start": 2145.119,
      "duration": 5.401
    },
    {
      "text": "is the city stood the so the first input",
      "start": 2147.72,
      "duration": 5.119
    },
    {
      "text": "is in the heart of the second is the",
      "start": 2150.52,
      "duration": 4.12
    },
    {
      "text": "city stood the which means that the",
      "start": 2152.839,
      "duration": 4.52
    },
    {
      "text": "stride is also equal to four so the",
      "start": 2154.64,
      "duration": 4.76
    },
    {
      "text": "first first input was this and then we",
      "start": 2157.359,
      "duration": 5.081
    },
    {
      "text": "moved and then the because the stride",
      "start": 2159.4,
      "duration": 5.56
    },
    {
      "text": "was four the second was the second input",
      "start": 2162.44,
      "duration": 4.96
    },
    {
      "text": "was the it stood the if the stride was",
      "start": 2164.96,
      "duration": 4.72
    },
    {
      "text": "equal to one the the next input would",
      "start": 2167.4,
      "duration": 4.08
    },
    {
      "text": "have been the heart of the",
      "start": 2169.68,
      "duration": 4.48
    },
    {
      "text": "city but that is not the second input",
      "start": 2171.48,
      "duration": 4.68
    },
    {
      "text": "here which means we have used a stride",
      "start": 2174.16,
      "duration": 3.959
    },
    {
      "text": "of four in this",
      "start": 2176.16,
      "duration": 4.199
    },
    {
      "text": "example that's why we also need the",
      "start": 2178.119,
      "duration": 4.041
    },
    {
      "text": "stride because we need to know how much",
      "start": 2180.359,
      "duration": 4.0
    },
    {
      "text": "to slide when to create the next input",
      "start": 2182.16,
      "duration": 4.6
    },
    {
      "text": "output batch I hope you have understood",
      "start": 2184.359,
      "duration": 4.081
    },
    {
      "text": "this part this is a bit of a tricky",
      "start": 2186.76,
      "duration": 3.76
    },
    {
      "text": "portion so please ask in the comment",
      "start": 2188.44,
      "duration": 4.32
    },
    {
      "text": "section if something is unclear over",
      "start": 2190.52,
      "duration": 5.2
    },
    {
      "text": "here so until this part we have created",
      "start": 2192.76,
      "duration": 5.48
    },
    {
      "text": "the input output tensor but now we have",
      "start": 2195.72,
      "duration": 4.399
    },
    {
      "text": "to define a method which is called as",
      "start": 2198.24,
      "duration": 4.8
    },
    {
      "text": "get item what this method does is that",
      "start": 2200.119,
      "duration": 4.841
    },
    {
      "text": "based on the index which we provide it",
      "start": 2203.04,
      "duration": 4.16
    },
    {
      "text": "just Returns the that particular row of",
      "start": 2204.96,
      "duration": 4.08
    },
    {
      "text": "the input and that particular row of the",
      "start": 2207.2,
      "duration": 4.56
    },
    {
      "text": "output so if the index is equal to zero",
      "start": 2209.04,
      "duration": 4.319
    },
    {
      "text": "this will return the first row of the",
      "start": 2211.76,
      "duration": 3.4
    },
    {
      "text": "input tensor and the first row of the",
      "start": 2213.359,
      "duration": 5.0
    },
    {
      "text": "output tensor why is this method get",
      "start": 2215.16,
      "duration": 5.24
    },
    {
      "text": "item needed because when we create a",
      "start": 2218.359,
      "duration": 4.96
    },
    {
      "text": "data loader the data loader will look at",
      "start": 2220.4,
      "duration": 5.8
    },
    {
      "text": "this method and then only it will create",
      "start": 2223.319,
      "duration": 5.401
    },
    {
      "text": "the input output pairs so if you look at",
      "start": 2226.2,
      "duration": 6.28
    },
    {
      "text": "the data loader what uh it needs the",
      "start": 2228.72,
      "duration": 5.52
    },
    {
      "text": "data set in this map style or the",
      "start": 2232.48,
      "duration": 4.04
    },
    {
      "text": "iterable style right now we are using a",
      "start": 2234.24,
      "duration": 4.04
    },
    {
      "text": "map style data set which means we need",
      "start": 2236.52,
      "duration": 4.64
    },
    {
      "text": "to have this get item what the get item",
      "start": 2238.28,
      "duration": 5.44
    },
    {
      "text": "will do is that it will actually tell it",
      "start": 2241.16,
      "duration": 6.52
    },
    {
      "text": "will tell the data loader uh what what",
      "start": 2243.72,
      "duration": 7.2
    },
    {
      "text": "kind of input and Target should we have",
      "start": 2247.68,
      "duration": 6.12
    },
    {
      "text": "so here we are clearly saying that if",
      "start": 2250.92,
      "duration": 5.0
    },
    {
      "text": "it's based on the index if the index is",
      "start": 2253.8,
      "duration": 5.0
    },
    {
      "text": "50 the input will be the 50th row of the",
      "start": 2255.92,
      "duration": 5.52
    },
    {
      "text": "input tensor the target will be the 50th",
      "start": 2258.8,
      "duration": 5.88
    },
    {
      "text": "row of the output tensor so this G item",
      "start": 2261.44,
      "duration": 5.639
    },
    {
      "text": "is finally what the data loader will be",
      "start": 2264.68,
      "duration": 4.88
    },
    {
      "text": "using now let me recap what all we have",
      "start": 2267.079,
      "duration": 5.601
    },
    {
      "text": "learned so far so this GPT data set",
      "start": 2269.56,
      "duration": 5.519
    },
    {
      "text": "origin class we have just implemented is",
      "start": 2272.68,
      "duration": 5.08
    },
    {
      "text": "based on the pytor data set class it",
      "start": 2275.079,
      "duration": 4.801
    },
    {
      "text": "defines how individual rows are fetched",
      "start": 2277.76,
      "duration": 5.319
    },
    {
      "text": "from the data set each row consists of",
      "start": 2279.88,
      "duration": 6.12
    },
    {
      "text": "number of token IDs assigned to an input",
      "start": 2283.079,
      "duration": 5.841
    },
    {
      "text": "chunk tensor this basically means that",
      "start": 2286.0,
      "duration": 5.52
    },
    {
      "text": "each row the length of or the number of",
      "start": 2288.92,
      "duration": 4.72
    },
    {
      "text": "tokens in each row is equal to the",
      "start": 2291.52,
      "duration": 4.76
    },
    {
      "text": "context length so here if you see the",
      "start": 2293.64,
      "duration": 4.92
    },
    {
      "text": "number of tokens in each row in the",
      "start": 2296.28,
      "duration": 4.72
    },
    {
      "text": "heart of four tokens because the context",
      "start": 2298.56,
      "duration": 5.08
    },
    {
      "text": "size is four the target chunk tensor",
      "start": 2301.0,
      "duration": 4.64
    },
    {
      "text": "contains the corresponding",
      "start": 2303.64,
      "duration": 5.479
    },
    {
      "text": "targets so uh as I've mentioned over",
      "start": 2305.64,
      "duration": 5.8
    },
    {
      "text": "here I'll actually upload the links to",
      "start": 2309.119,
      "duration": 5.561
    },
    {
      "text": "this data set data loader and also maybe",
      "start": 2311.44,
      "duration": 7.399
    },
    {
      "text": "uh a small tutorial so that uh you know",
      "start": 2314.68,
      "duration": 6.04
    },
    {
      "text": "this thing becomes a bit more clearer",
      "start": 2318.839,
      "duration": 3.801
    },
    {
      "text": "and I think you should have a stronger",
      "start": 2320.72,
      "duration": 4.68
    },
    {
      "text": "understanding of uh this data set and",
      "start": 2322.64,
      "duration": 4.52
    },
    {
      "text": "data loader portion because many people",
      "start": 2325.4,
      "duration": 4.36
    },
    {
      "text": "just skip over this completely now what",
      "start": 2327.16,
      "duration": 4.56
    },
    {
      "text": "we'll be doing since our data set is",
      "start": 2329.76,
      "duration": 4.04
    },
    {
      "text": "ready and this format is ready we will",
      "start": 2331.72,
      "duration": 5.08
    },
    {
      "text": "feed the data set into the data loader",
      "start": 2333.8,
      "duration": 4.68
    },
    {
      "text": "so this is where the data loader comes",
      "start": 2336.8,
      "duration": 4.4
    },
    {
      "text": "into the picture and what we'll be doing",
      "start": 2338.48,
      "duration": 4.72
    },
    {
      "text": "is we'll be doing the four things we'll",
      "start": 2341.2,
      "duration": 4.36
    },
    {
      "text": "initialize the tokenizer create the data",
      "start": 2343.2,
      "duration": 6.96
    },
    {
      "text": "set why because this data set needs this",
      "start": 2345.56,
      "duration": 7.279
    },
    {
      "text": "class needs four attributes the the text",
      "start": 2350.16,
      "duration": 4.76
    },
    {
      "text": "the tokenizer the max length and the",
      "start": 2352.839,
      "duration": 4.401
    },
    {
      "text": "stride then what we'll be doing is that",
      "start": 2354.92,
      "duration": 5.24
    },
    {
      "text": "we'll put drop last equal to true",
      "start": 2357.24,
      "duration": 5.28
    },
    {
      "text": "because if the last batch it's shorter",
      "start": 2360.16,
      "duration": 5.52
    },
    {
      "text": "than the batch size uh it's dropped to",
      "start": 2362.52,
      "duration": 5.28
    },
    {
      "text": "prevent loss spikes during training you",
      "start": 2365.68,
      "duration": 4.0
    },
    {
      "text": "don't need to know about this too much",
      "start": 2367.8,
      "duration": 3.84
    },
    {
      "text": "but just remember that when we do batch",
      "start": 2369.68,
      "duration": 4.48
    },
    {
      "text": "processing if the last batch is shorter",
      "start": 2371.64,
      "duration": 5.64
    },
    {
      "text": "than the specified batch size uh it is",
      "start": 2374.16,
      "duration": 5.24
    },
    {
      "text": "important to prevent loss spikes during",
      "start": 2377.28,
      "duration": 6.72
    },
    {
      "text": "the training process awesome so now we",
      "start": 2379.4,
      "duration": 6.64
    },
    {
      "text": "Define this function called create data",
      "start": 2384.0,
      "duration": 4.72
    },
    {
      "text": "loader this is very important because",
      "start": 2386.04,
      "duration": 4.44
    },
    {
      "text": "this is the one this function will",
      "start": 2388.72,
      "duration": 3.44
    },
    {
      "text": "implement the batch processing the",
      "start": 2390.48,
      "duration": 4.4
    },
    {
      "text": "parallel processing which we will need",
      "start": 2392.16,
      "duration": 4.52
    },
    {
      "text": "uh and that is governed by the batch",
      "start": 2394.88,
      "duration": 4.08
    },
    {
      "text": "size but more than that what this",
      "start": 2396.68,
      "duration": 4.12
    },
    {
      "text": "function will do is that it will",
      "start": 2398.96,
      "duration": 4.52
    },
    {
      "text": "actually create uh it will help us",
      "start": 2400.8,
      "duration": 6.08
    },
    {
      "text": "create the input output uh data pairs",
      "start": 2403.48,
      "duration": 6.24
    },
    {
      "text": "from the data set which we defined",
      "start": 2406.88,
      "duration": 4.92
    },
    {
      "text": "earlier awesome so let's see the",
      "start": 2409.72,
      "duration": 3.92
    },
    {
      "text": "arguments which this function takes it",
      "start": 2411.8,
      "duration": 3.76
    },
    {
      "text": "of course takes the text file which is",
      "start": 2413.64,
      "duration": 5.0
    },
    {
      "text": "the data set which we have then it takes",
      "start": 2415.56,
      "duration": 5.799
    },
    {
      "text": "the batch size which is how many batches",
      "start": 2418.64,
      "duration": 5.16
    },
    {
      "text": "how many CPU processes we want to run",
      "start": 2421.359,
      "duration": 4.881
    },
    {
      "text": "parallell if you don't specify anything",
      "start": 2423.8,
      "duration": 4.559
    },
    {
      "text": "this will be by default four so if the",
      "start": 2426.24,
      "duration": 4.119
    },
    {
      "text": "number of threads on your CPU are four",
      "start": 2428.359,
      "duration": 3.801
    },
    {
      "text": "or eight you can run those many",
      "start": 2430.359,
      "duration": 2.921
    },
    {
      "text": "processes",
      "start": 2432.16,
      "duration": 4.24
    },
    {
      "text": "parallely max length is basically equal",
      "start": 2433.28,
      "duration": 5.319
    },
    {
      "text": "to the context length so we here I",
      "start": 2436.4,
      "duration": 4.959
    },
    {
      "text": "showed you a context length of four uh",
      "start": 2438.599,
      "duration": 6.24
    },
    {
      "text": "but when gpt2 or gpt3 those high level",
      "start": 2441.359,
      "duration": 5.72
    },
    {
      "text": "llm models are designed they usually",
      "start": 2444.839,
      "duration": 5.081
    },
    {
      "text": "Implement a context length of 256 which",
      "start": 2447.079,
      "duration": 4.601
    },
    {
      "text": "means they are so strong that the model",
      "start": 2449.92,
      "duration": 3.919
    },
    {
      "text": "can look at 256 words and predict the",
      "start": 2451.68,
      "duration": 3.679
    },
    {
      "text": "next word during",
      "start": 2453.839,
      "duration": 4.48
    },
    {
      "text": "training then stride is one 28 so stride",
      "start": 2455.359,
      "duration": 4.921
    },
    {
      "text": "as I mentioned is when we create input",
      "start": 2458.319,
      "duration": 4.201
    },
    {
      "text": "output batches how much we need to skip",
      "start": 2460.28,
      "duration": 5.16
    },
    {
      "text": "before we create the next batch a number",
      "start": 2462.52,
      "duration": 4.96
    },
    {
      "text": "of workers is also the number of CPU",
      "start": 2465.44,
      "duration": 5.639
    },
    {
      "text": "threads which we which we can run",
      "start": 2467.48,
      "duration": 6.04
    },
    {
      "text": "simultaneously awesome so the first",
      "start": 2471.079,
      "duration": 3.641
    },
    {
      "text": "thing which we do is Define the",
      "start": 2473.52,
      "duration": 3.28
    },
    {
      "text": "tokenizer and here we are using the tick",
      "start": 2474.72,
      "duration": 4.2
    },
    {
      "text": "token which is the bite pair encoder",
      "start": 2476.8,
      "duration": 5.08
    },
    {
      "text": "used by GPT and then we create the data",
      "start": 2478.92,
      "duration": 4.6
    },
    {
      "text": "set so here see we are creating an",
      "start": 2481.88,
      "duration": 4.68
    },
    {
      "text": "instance of this GPT data set V1 class",
      "start": 2483.52,
      "duration": 5.839
    },
    {
      "text": "which we defined over here uh and here",
      "start": 2486.56,
      "duration": 5.08
    },
    {
      "text": "we provide the input text the tokenizer",
      "start": 2489.359,
      "duration": 3.841
    },
    {
      "text": "is this tick token which is the bite",
      "start": 2491.64,
      "duration": 4.439
    },
    {
      "text": "pair encoding the max length is 256 and",
      "start": 2493.2,
      "duration": 5.84
    },
    {
      "text": "the stride is 128 awesome so an instance",
      "start": 2496.079,
      "duration": 5.52
    },
    {
      "text": "of the GPT data set one is created and",
      "start": 2499.04,
      "duration": 5.44
    },
    {
      "text": "we are calling it data set this data set",
      "start": 2501.599,
      "duration": 5.161
    },
    {
      "text": "is then feeded or loaded into the data",
      "start": 2504.48,
      "duration": 4.879
    },
    {
      "text": "loader look at this data loader method",
      "start": 2506.76,
      "duration": 5.24
    },
    {
      "text": "it's it's it takes the data set as an",
      "start": 2509.359,
      "duration": 4.641
    },
    {
      "text": "attribute basically what is happening in",
      "start": 2512.0,
      "duration": 4.64
    },
    {
      "text": "this step is that this data loader will",
      "start": 2514.0,
      "duration": 5.96
    },
    {
      "text": "just check this get item method in this",
      "start": 2516.64,
      "duration": 6.08
    },
    {
      "text": "in this class and then it will return",
      "start": 2519.96,
      "duration": 4.8
    },
    {
      "text": "the input output pairs basically based",
      "start": 2522.72,
      "duration": 4.76
    },
    {
      "text": "on what is mentioned in the get item",
      "start": 2524.76,
      "duration": 5.04
    },
    {
      "text": "that is exactly how it's going to work",
      "start": 2527.48,
      "duration": 4.119
    },
    {
      "text": "and then we just return the data loader",
      "start": 2529.8,
      "duration": 3.48
    },
    {
      "text": "which are the input output pairs that's",
      "start": 2531.599,
      "duration": 5.641
    },
    {
      "text": "it which is happening over here so uh",
      "start": 2533.28,
      "duration": 6.0
    },
    {
      "text": "essentially in this part what we did was",
      "start": 2537.24,
      "duration": 5.119
    },
    {
      "text": "we implemented a a data set which is a",
      "start": 2539.28,
      "duration": 6.2
    },
    {
      "text": "method or rather I would say it's a",
      "start": 2542.359,
      "duration": 6.281
    },
    {
      "text": "library python and then what we are",
      "start": 2545.48,
      "duration": 4.96
    },
    {
      "text": "going to do is that we also implemented",
      "start": 2548.64,
      "duration": 4.04
    },
    {
      "text": "the data loader so the data set was",
      "start": 2550.44,
      "duration": 4.72
    },
    {
      "text": "initially implemented and we created a",
      "start": 2552.68,
      "duration": 5.72
    },
    {
      "text": "class called GPT data set V1 an instance",
      "start": 2555.16,
      "duration": 5.08
    },
    {
      "text": "of this class was created and then it",
      "start": 2558.4,
      "duration": 4.919
    },
    {
      "text": "was fed to the data loader method what",
      "start": 2560.24,
      "duration": 4.96
    },
    {
      "text": "this method essentially did was it",
      "start": 2563.319,
      "duration": 4.121
    },
    {
      "text": "accessed the get item and then",
      "start": 2565.2,
      "duration": 3.72
    },
    {
      "text": "essentially what it's going to do it's",
      "start": 2567.44,
      "duration": 3.32
    },
    {
      "text": "just going to create those input output",
      "start": 2568.92,
      "duration": 4.439
    },
    {
      "text": "tensors which we have defined in the GPT",
      "start": 2570.76,
      "duration": 5.079
    },
    {
      "text": "data set V1 class why did we do this",
      "start": 2573.359,
      "duration": 4.441
    },
    {
      "text": "data loader between because it will",
      "start": 2575.839,
      "duration": 4.841
    },
    {
      "text": "really help us to do parallel processing",
      "start": 2577.8,
      "duration": 5.72
    },
    {
      "text": "and it can also uh analyze multiple",
      "start": 2580.68,
      "duration": 5.2
    },
    {
      "text": "batches at one time so here I want to",
      "start": 2583.52,
      "duration": 3.88
    },
    {
      "text": "explain the difference between batch",
      "start": 2585.88,
      "duration": 3.64
    },
    {
      "text": "size and number of workers so there is a",
      "start": 2587.4,
      "duration": 3.76
    },
    {
      "text": "difference between batch size and the",
      "start": 2589.52,
      "duration": 3.799
    },
    {
      "text": "number of workers batch size is",
      "start": 2591.16,
      "duration": 6.159
    },
    {
      "text": "basically the number of uh batches the",
      "start": 2593.319,
      "duration": 6.321
    },
    {
      "text": "model processes at once before updating",
      "start": 2597.319,
      "duration": 5.121
    },
    {
      "text": "its parameters so to make sure that the",
      "start": 2599.64,
      "duration": 5.08
    },
    {
      "text": "model updates its parameters quickly the",
      "start": 2602.44,
      "duration": 4.919
    },
    {
      "text": "data is usually chunked into batches so",
      "start": 2604.72,
      "duration": 5.2
    },
    {
      "text": "that after analyzing four batches in",
      "start": 2607.359,
      "duration": 4.121
    },
    {
      "text": "this case the model will update its",
      "start": 2609.92,
      "duration": 3.199
    },
    {
      "text": "parameters rather than going through the",
      "start": 2611.48,
      "duration": 4.359
    },
    {
      "text": "entire data set num workers is different",
      "start": 2613.119,
      "duration": 4.881
    },
    {
      "text": "it is basically for parallel processing",
      "start": 2615.839,
      "duration": 3.921
    },
    {
      "text": "on different threads of your",
      "start": 2618.0,
      "duration": 4.72
    },
    {
      "text": "CPU uh and data loader enables us to do",
      "start": 2619.76,
      "duration": 4.799
    },
    {
      "text": "all this if we did not do this then",
      "start": 2622.72,
      "duration": 3.68
    },
    {
      "text": "defining the batch size num workers",
      "start": 2624.559,
      "duration": 3.601
    },
    {
      "text": "would be very",
      "start": 2626.4,
      "duration": 4.0
    },
    {
      "text": "challenging now what we are going to do",
      "start": 2628.16,
      "duration": 3.84
    },
    {
      "text": "we are going to test the data loader",
      "start": 2630.4,
      "duration": 4.08
    },
    {
      "text": "with a batch size of one and a context",
      "start": 2632.0,
      "duration": 5.359
    },
    {
      "text": "size of four this will develop an intu",
      "start": 2634.48,
      "duration": 5.44
    },
    {
      "text": "of how the data set V1 class and the",
      "start": 2637.359,
      "duration": 4.76
    },
    {
      "text": "create data loader function work",
      "start": 2639.92,
      "duration": 4.56
    },
    {
      "text": "together so if you found the previous",
      "start": 2642.119,
      "duration": 4.2
    },
    {
      "text": "part a bit challenging to understand",
      "start": 2644.48,
      "duration": 4.2
    },
    {
      "text": "please try to focus on this part where",
      "start": 2646.319,
      "duration": 4.121
    },
    {
      "text": "we are going to show the Hands-On",
      "start": 2648.68,
      "duration": 4.08
    },
    {
      "text": "implementation of the data set class and",
      "start": 2650.44,
      "duration": 5.28
    },
    {
      "text": "the create data loader function so first",
      "start": 2652.76,
      "duration": 5.24
    },
    {
      "text": "what we do here we just read the",
      "start": 2655.72,
      "duration": 5.56
    },
    {
      "text": "text uh and then we are going to create",
      "start": 2658.0,
      "duration": 5.079
    },
    {
      "text": "a data loader and convert the data",
      "start": 2661.28,
      "duration": 4.68
    },
    {
      "text": "loader into python iterator to fetch the",
      "start": 2663.079,
      "duration": 4.76
    },
    {
      "text": "next entry in the data",
      "start": 2665.96,
      "duration": 4.2
    },
    {
      "text": "let me show you what this means so here",
      "start": 2667.839,
      "duration": 3.801
    },
    {
      "text": "what we are doing is we are going to",
      "start": 2670.16,
      "duration": 4.08
    },
    {
      "text": "create the data loader but with a batch",
      "start": 2671.64,
      "duration": 5.16
    },
    {
      "text": "size of one and a context size of",
      "start": 2674.24,
      "duration": 5.0
    },
    {
      "text": "four then what we are going to do we are",
      "start": 2676.8,
      "duration": 4.36
    },
    {
      "text": "going to iterate through the uh data",
      "start": 2679.24,
      "duration": 4.0
    },
    {
      "text": "loader and we are going to print the",
      "start": 2681.16,
      "duration": 4.48
    },
    {
      "text": "first batch and I I want to show you",
      "start": 2683.24,
      "duration": 4.04
    },
    {
      "text": "what this batch looks like so I'm just",
      "start": 2685.64,
      "duration": 4.28
    },
    {
      "text": "going to print this uh and here you see",
      "start": 2687.28,
      "duration": 5.2
    },
    {
      "text": "this is the printed answer so what the",
      "start": 2689.92,
      "duration": 4.72
    },
    {
      "text": "first batch basically gave me is the",
      "start": 2692.48,
      "duration": 4.28
    },
    {
      "text": "input tensor and the output tensor",
      "start": 2694.64,
      "duration": 4.52
    },
    {
      "text": "that's it so this is the input tensor",
      "start": 2696.76,
      "duration": 4.16
    },
    {
      "text": "and when you shift it by one you get the",
      "start": 2699.16,
      "duration": 4.399
    },
    {
      "text": "output tensor that's it essentially we",
      "start": 2700.92,
      "duration": 4.72
    },
    {
      "text": "did all this to get this input output",
      "start": 2703.559,
      "duration": 4.52
    },
    {
      "text": "pair which we had already seen before so",
      "start": 2705.64,
      "duration": 4.28
    },
    {
      "text": "if you look at the input output pair",
      "start": 2708.079,
      "duration": 6.361
    },
    {
      "text": "it's very similar to um the input output",
      "start": 2709.92,
      "duration": 6.439
    },
    {
      "text": "pair which we had looked at the",
      "start": 2714.44,
      "duration": 3.96
    },
    {
      "text": "beginning of this lecture so if you",
      "start": 2716.359,
      "duration": 4.0
    },
    {
      "text": "remember at the beginning of this",
      "start": 2718.4,
      "duration": 3.6
    },
    {
      "text": "lecture we had looked at this input",
      "start": 2720.359,
      "duration": 5.96
    },
    {
      "text": "output pair 1 2 3 4 uh and then 2 3 4 5",
      "start": 2722.0,
      "duration": 6.359
    },
    {
      "text": "right what we have essentially obtained",
      "start": 2726.319,
      "duration": 4.121
    },
    {
      "text": "right now is exactly similar but through",
      "start": 2728.359,
      "duration": 4.601
    },
    {
      "text": "the data loader so it's much more",
      "start": 2730.44,
      "duration": 4.679
    },
    {
      "text": "structured and here we can specify a lot",
      "start": 2732.96,
      "duration": 4.96
    },
    {
      "text": "more parameters like batch size maximum",
      "start": 2735.119,
      "duration": 5.401
    },
    {
      "text": "length stride so here the stride is",
      "start": 2737.92,
      "duration": 5.72
    },
    {
      "text": "equal to one we uh we can even show you",
      "start": 2740.52,
      "duration": 6.28
    },
    {
      "text": "the effect of stride so let me actually",
      "start": 2743.64,
      "duration": 5.04
    },
    {
      "text": "show you the figure to",
      "start": 2746.8,
      "duration": 4.84
    },
    {
      "text": "explain uh what actually changing the",
      "start": 2748.68,
      "duration": 7.08
    },
    {
      "text": "stride really looks like so um here is",
      "start": 2751.64,
      "duration": 6.64
    },
    {
      "text": "the figure for explaining The Stride in",
      "start": 2755.76,
      "duration": 5.319
    },
    {
      "text": "some detail",
      "start": 2758.28,
      "duration": 2.799
    },
    {
      "text": "yeah okay so if you look at this",
      "start": 2761.16,
      "duration": 4.24
    },
    {
      "text": "figure okay so let's look at this figure",
      "start": 2769.04,
      "duration": 5.6
    },
    {
      "text": "the first part of this figure shows the",
      "start": 2772.079,
      "duration": 6.121
    },
    {
      "text": "input stride of uh one and the second",
      "start": 2774.64,
      "duration": 5.16
    },
    {
      "text": "part of this figure shows the input",
      "start": 2778.2,
      "duration": 3.919
    },
    {
      "text": "stride of four so if you look at the",
      "start": 2779.8,
      "duration": 5.08
    },
    {
      "text": "first figure the first input of batch",
      "start": 2782.119,
      "duration": 4.601
    },
    {
      "text": "the input of batch one is in the heart",
      "start": 2784.88,
      "duration": 4.439
    },
    {
      "text": "of and the input of batch two is the",
      "start": 2786.72,
      "duration": 4.92
    },
    {
      "text": "heart of the so see there is just a",
      "start": 2789.319,
      "duration": 5.641
    },
    {
      "text": "stride of one year between batches",
      "start": 2791.64,
      "duration": 5.4
    },
    {
      "text": "between inputs of different batches but",
      "start": 2794.96,
      "duration": 4.159
    },
    {
      "text": "if you look at the second figure the",
      "start": 2797.04,
      "duration": 4.4
    },
    {
      "text": "input of batch one is in the heart of",
      "start": 2799.119,
      "duration": 4.561
    },
    {
      "text": "which is this and then you stride by",
      "start": 2801.44,
      "duration": 5.32
    },
    {
      "text": "four 1 2 3 and four so the next input",
      "start": 2803.68,
      "duration": 5.439
    },
    {
      "text": "will be the city stood the",
      "start": 2806.76,
      "duration": 6.0
    },
    {
      "text": "see so typically a more stride means",
      "start": 2809.119,
      "duration": 6.521
    },
    {
      "text": "that you you move over the data in a",
      "start": 2812.76,
      "duration": 4.96
    },
    {
      "text": "faster Manner and so less computations",
      "start": 2815.64,
      "duration": 5.16
    },
    {
      "text": "will be there that's what you specify",
      "start": 2817.72,
      "duration": 5.24
    },
    {
      "text": "When you mention the stride so here",
      "start": 2820.8,
      "duration": 4.12
    },
    {
      "text": "stride is equal to one which which means",
      "start": 2822.96,
      "duration": 3.84
    },
    {
      "text": "that we'll be doing something very",
      "start": 2824.92,
      "duration": 6.639
    },
    {
      "text": "similar to uh what is mentioned in this",
      "start": 2826.8,
      "duration": 6.519
    },
    {
      "text": "uh example which I'm highlighting with a",
      "start": 2831.559,
      "duration": 3.081
    },
    {
      "text": "star right",
      "start": 2833.319,
      "duration": 4.0
    },
    {
      "text": "now awesome so here is how we create the",
      "start": 2834.64,
      "duration": 4.479
    },
    {
      "text": "input and output",
      "start": 2837.319,
      "duration": 4.28
    },
    {
      "text": "batches so what I want to mention here",
      "start": 2839.119,
      "duration": 4.321
    },
    {
      "text": "is that the first batch variable",
      "start": 2841.599,
      "duration": 3.881
    },
    {
      "text": "contains two tensors the first tensor",
      "start": 2843.44,
      "duration": 4.679
    },
    {
      "text": "stores the input token ID these and the",
      "start": 2845.48,
      "duration": 5.24
    },
    {
      "text": "second St tenser stores the target token",
      "start": 2848.119,
      "duration": 4.081
    },
    {
      "text": "IDs which are",
      "start": 2850.72,
      "duration": 4.32
    },
    {
      "text": "these and since the max length is set to",
      "start": 2852.2,
      "duration": 5.399
    },
    {
      "text": "four each of the two tensors contain",
      "start": 2855.04,
      "duration": 5.44
    },
    {
      "text": "four token IDs that is also very very",
      "start": 2857.599,
      "duration": 5.72
    },
    {
      "text": "important to remember note that an input",
      "start": 2860.48,
      "duration": 5.52
    },
    {
      "text": "size of four is relatively small uh or",
      "start": 2863.319,
      "duration": 5.04
    },
    {
      "text": "the context size it is common to train",
      "start": 2866.0,
      "duration": 4.68
    },
    {
      "text": "llms with input sizes or context sizes",
      "start": 2868.359,
      "duration": 3.641
    },
    {
      "text": "of at least",
      "start": 2870.68,
      "duration": 3.76
    },
    {
      "text": "256 now you can also see the second",
      "start": 2872.0,
      "duration": 5.559
    },
    {
      "text": "batch see the second batch is 367",
      "start": 2874.44,
      "duration": 5.56
    },
    {
      "text": "2885 and this is the output of the",
      "start": 2877.559,
      "duration": 4.361
    },
    {
      "text": "second batch so the second batch input",
      "start": 2880.0,
      "duration": 4.2
    },
    {
      "text": "is this the second batch output is",
      "start": 2881.92,
      "duration": 5.199
    },
    {
      "text": "this so if you compare the First with",
      "start": 2884.2,
      "duration": 4.96
    },
    {
      "text": "the second batch we can see that the",
      "start": 2887.119,
      "duration": 4.2
    },
    {
      "text": "second batch token IDs are just shifted",
      "start": 2889.16,
      "duration": 4.52
    },
    {
      "text": "with one position see this is the first",
      "start": 2891.319,
      "duration": 4.441
    },
    {
      "text": "batch input token IDs this is the second",
      "start": 2893.68,
      "duration": 4.48
    },
    {
      "text": "batch input token IDs now can you think",
      "start": 2895.76,
      "duration": 4.16
    },
    {
      "text": "what would be the stride in this case",
      "start": 2898.16,
      "duration": 3.32
    },
    {
      "text": "based on the explanation which I",
      "start": 2899.92,
      "duration": 3.88
    },
    {
      "text": "provided to",
      "start": 2901.48,
      "duration": 5.04
    },
    {
      "text": "you the stride will be equal to one",
      "start": 2903.8,
      "duration": 5.279
    },
    {
      "text": "because because if you look at the first",
      "start": 2906.52,
      "duration": 4.44
    },
    {
      "text": "input batch and the second input batch",
      "start": 2909.079,
      "duration": 4.441
    },
    {
      "text": "it just shifted by",
      "start": 2910.96,
      "duration": 7.399
    },
    {
      "text": "one um so the stride setting dictates",
      "start": 2913.52,
      "duration": 7.64
    },
    {
      "text": "the number of position the input shift",
      "start": 2918.359,
      "duration": 4.76
    },
    {
      "text": "across batches emulating a sliding",
      "start": 2921.16,
      "duration": 3.679
    },
    {
      "text": "window approach that's why it's called",
      "start": 2923.119,
      "duration": 4.48
    },
    {
      "text": "as the sliding window approach batch",
      "start": 2924.839,
      "duration": 4.681
    },
    {
      "text": "sizes of one such as we have sampled",
      "start": 2927.599,
      "duration": 4.121
    },
    {
      "text": "from the data loader so far are used for",
      "start": 2929.52,
      "duration": 4.92
    },
    {
      "text": "illustration purposes if you have",
      "start": 2931.72,
      "duration": 4.56
    },
    {
      "text": "previous experience with deep learning",
      "start": 2934.44,
      "duration": 3.679
    },
    {
      "text": "you may know that small batch sizes",
      "start": 2936.28,
      "duration": 3.96
    },
    {
      "text": "require less memory but lead to more",
      "start": 2938.119,
      "duration": 5.281
    },
    {
      "text": "noisy model updates just like in regular",
      "start": 2940.24,
      "duration": 5.2
    },
    {
      "text": "deep learning the batch size is a",
      "start": 2943.4,
      "duration": 3.76
    },
    {
      "text": "trade-off and hyperparameter to",
      "start": 2945.44,
      "duration": 4.359
    },
    {
      "text": "experiment when training llms so as I",
      "start": 2947.16,
      "duration": 5.0
    },
    {
      "text": "mentioned the batch size is number of",
      "start": 2949.799,
      "duration": 4.721
    },
    {
      "text": "data the model has to process before",
      "start": 2952.16,
      "duration": 4.6
    },
    {
      "text": "updating its parameters so if the batch",
      "start": 2954.52,
      "duration": 4.079
    },
    {
      "text": "size is very small the parameter updates",
      "start": 2956.76,
      "duration": 3.52
    },
    {
      "text": "will be very quick but the updates will",
      "start": 2958.599,
      "duration": 4.401
    },
    {
      "text": "be noisy if the batch size is very large",
      "start": 2960.28,
      "duration": 4.16
    },
    {
      "text": "the model will be going through the",
      "start": 2963.0,
      "duration": 4.359
    },
    {
      "text": "entire data set before",
      "start": 2964.44,
      "duration": 4.32
    },
    {
      "text": "or the model will be going through the",
      "start": 2967.359,
      "duration": 3.881
    },
    {
      "text": "large batch before making the update so",
      "start": 2968.76,
      "duration": 4.4
    },
    {
      "text": "the update will not be as noisy but it",
      "start": 2971.24,
      "duration": 4.319
    },
    {
      "text": "will take a lot of time so you need to",
      "start": 2973.16,
      "duration": 5.76
    },
    {
      "text": "make sure this hyper parameter is set",
      "start": 2975.559,
      "duration": 6.481
    },
    {
      "text": "correctly before we move on uh and end",
      "start": 2978.92,
      "duration": 4.8
    },
    {
      "text": "this lecture the last thing which I want",
      "start": 2982.04,
      "duration": 5.039
    },
    {
      "text": "to show you is the effect of batch",
      "start": 2983.72,
      "duration": 6.28
    },
    {
      "text": "size uh so let's actually take a brief",
      "start": 2987.079,
      "duration": 7.441
    },
    {
      "text": "look at that essentially uh what happens",
      "start": 2990.0,
      "duration": 7.0
    },
    {
      "text": "when the batch size is more than one so",
      "start": 2994.52,
      "duration": 4.279
    },
    {
      "text": "the batch size so here you see I'm",
      "start": 2997.0,
      "duration": 3.92
    },
    {
      "text": "creating a data loader with a batch size",
      "start": 2998.799,
      "duration": 4.8
    },
    {
      "text": "equal to 8 and then I'm running this so",
      "start": 3000.92,
      "duration": 4.52
    },
    {
      "text": "see the input tensor and the output",
      "start": 3003.599,
      "duration": 4.121
    },
    {
      "text": "tensor and here I'm also incre",
      "start": 3005.44,
      "duration": 4.52
    },
    {
      "text": "increasing the stride to four so if you",
      "start": 3007.72,
      "duration": 4.599
    },
    {
      "text": "look at the first input and the second",
      "start": 3009.96,
      "duration": 4.04
    },
    {
      "text": "input you will see that there is not an",
      "start": 3012.319,
      "duration": 4.081
    },
    {
      "text": "overlap because the side stride is equal",
      "start": 3014.0,
      "duration": 3.359
    },
    {
      "text": "to",
      "start": 3016.4,
      "duration": 3.52
    },
    {
      "text": "four and here the batch size is equal to",
      "start": 3017.359,
      "duration": 5.041
    },
    {
      "text": "eight so see the input has essentially",
      "start": 3019.92,
      "duration": 5.72
    },
    {
      "text": "eight uh input tensor has eight inputs",
      "start": 3022.4,
      "duration": 5.439
    },
    {
      "text": "which means the batch size equal to 8",
      "start": 3025.64,
      "duration": 3.959
    },
    {
      "text": "and the output tensor will also have",
      "start": 3027.839,
      "duration": 3.561
    },
    {
      "text": "eight rows because the batch size is",
      "start": 3029.599,
      "duration": 3.76
    },
    {
      "text": "equal to eight so the model will",
      "start": 3031.4,
      "duration": 3.959
    },
    {
      "text": "essentially process this batch before",
      "start": 3033.359,
      "duration": 4.96
    },
    {
      "text": "making the parameter",
      "start": 3035.359,
      "duration": 6.881
    },
    {
      "text": "updates uh okay so now here you can see",
      "start": 3038.319,
      "duration": 5.681
    },
    {
      "text": "as I mentioned we have increased the",
      "start": 3042.24,
      "duration": 4.16
    },
    {
      "text": "stride to four this is to utilize the",
      "start": 3044.0,
      "duration": 3.44
    },
    {
      "text": "data set",
      "start": 3046.4,
      "duration": 4.6
    },
    {
      "text": "fully um we don't skip a single word but",
      "start": 3047.44,
      "duration": 6.56
    },
    {
      "text": "also avoid overlap between batches since",
      "start": 3051.0,
      "duration": 4.76
    },
    {
      "text": "more overlap could lead to increased",
      "start": 3054.0,
      "duration": 4.319
    },
    {
      "text": "overfitting so that is one advantage of",
      "start": 3055.76,
      "duration": 4.96
    },
    {
      "text": "having a more stride so here you see in",
      "start": 3058.319,
      "duration": 4.04
    },
    {
      "text": "these two examples if you look at the",
      "start": 3060.72,
      "duration": 4.0
    },
    {
      "text": "second if you look at the second example",
      "start": 3062.359,
      "duration": 4.76
    },
    {
      "text": "over here the stride is equal to four so",
      "start": 3064.72,
      "duration": 4.359
    },
    {
      "text": "there is no overlap between the input",
      "start": 3067.119,
      "duration": 4.361
    },
    {
      "text": "batch one and the input batch two which",
      "start": 3069.079,
      "duration": 4.441
    },
    {
      "text": "might be good for overfitting per uh",
      "start": 3071.48,
      "duration": 3.28
    },
    {
      "text": "which might be good to prevent",
      "start": 3073.52,
      "duration": 3.44
    },
    {
      "text": "overfitting whereas if you look look",
      "start": 3074.76,
      "duration": 3.28
    },
    {
      "text": "over",
      "start": 3076.96,
      "duration": 4.0
    },
    {
      "text": "here the stride is just equal to one so",
      "start": 3078.04,
      "duration": 4.88
    },
    {
      "text": "the input batch one and two have a lot",
      "start": 3080.96,
      "duration": 3.879
    },
    {
      "text": "of overlap that might lead to",
      "start": 3082.92,
      "duration": 5.52
    },
    {
      "text": "overfitting which is not great for",
      "start": 3084.839,
      "duration": 5.881
    },
    {
      "text": "training this actually brings us to the",
      "start": 3088.44,
      "duration": 4.24
    },
    {
      "text": "end of today's lecture where we covered",
      "start": 3090.72,
      "duration": 4.839
    },
    {
      "text": "number of things first we covered what",
      "start": 3092.68,
      "duration": 6.72
    },
    {
      "text": "does it mean to uh break down the text",
      "start": 3095.559,
      "duration": 7.081
    },
    {
      "text": "into input Target pairs input Target",
      "start": 3099.4,
      "duration": 5.399
    },
    {
      "text": "pairs are definitely needed for training",
      "start": 3102.64,
      "duration": 5.439
    },
    {
      "text": "of llms and we started with this example",
      "start": 3104.799,
      "duration": 6.0
    },
    {
      "text": "uh this example right here on the",
      "start": 3108.079,
      "duration": 6.201
    },
    {
      "text": "screen let me just take you to that yeah",
      "start": 3110.799,
      "duration": 7.401
    },
    {
      "text": "so we started with",
      "start": 3114.28,
      "duration": 3.92
    },
    {
      "text": "yeah so we started with this example to",
      "start": 3118.359,
      "duration": 5.48
    },
    {
      "text": "illustratively explain what the input",
      "start": 3121.92,
      "duration": 4.199
    },
    {
      "text": "Target pair looks like so the target",
      "start": 3123.839,
      "duration": 4.401
    },
    {
      "text": "pair is just the input which is shifted",
      "start": 3126.119,
      "duration": 4.96
    },
    {
      "text": "by one then we saw how to convert this",
      "start": 3128.24,
      "duration": 6.839
    },
    {
      "text": "into X and Y pairs so if the input is 1",
      "start": 3131.079,
      "duration": 7.161
    },
    {
      "text": "2 3 4 the output is 2 3 4 5 here the",
      "start": 3135.079,
      "duration": 5.801
    },
    {
      "text": "context size is four which means that if",
      "start": 3138.24,
      "duration": 4.92
    },
    {
      "text": "one is the input the output should be",
      "start": 3140.88,
      "duration": 4.439
    },
    {
      "text": "two if one and two is the input the",
      "start": 3143.16,
      "duration": 4.679
    },
    {
      "text": "output should be three if 1 2 3 is the",
      "start": 3145.319,
      "duration": 5.161
    },
    {
      "text": "input the output should be four if 1 2 3",
      "start": 3147.839,
      "duration": 5.441
    },
    {
      "text": "4 is the input the output should be five",
      "start": 3150.48,
      "duration": 5.2
    },
    {
      "text": "so in one input Target pair there are",
      "start": 3153.28,
      "duration": 4.96
    },
    {
      "text": "four computations or four predictions",
      "start": 3155.68,
      "duration": 4.879
    },
    {
      "text": "because the context size is four the",
      "start": 3158.24,
      "duration": 4.0
    },
    {
      "text": "rest of the lecture was devoted to",
      "start": 3160.559,
      "duration": 3.881
    },
    {
      "text": "creating input Target pairs like this",
      "start": 3162.24,
      "duration": 4.8
    },
    {
      "text": "but in a structured manner for that what",
      "start": 3164.44,
      "duration": 4.72
    },
    {
      "text": "we actually did was we used something",
      "start": 3167.04,
      "duration": 4.6
    },
    {
      "text": "which is called as data loader and then",
      "start": 3169.16,
      "duration": 5.28
    },
    {
      "text": "we paired the data loader with the data",
      "start": 3171.64,
      "duration": 6.04
    },
    {
      "text": "set so first we created this GPT data",
      "start": 3174.44,
      "duration": 6.359
    },
    {
      "text": "set V1 class uh we created a data set",
      "start": 3177.68,
      "duration": 5.0
    },
    {
      "text": "and then we fed that data set into the",
      "start": 3180.799,
      "duration": 4.04
    },
    {
      "text": "data loader what this data loer",
      "start": 3182.68,
      "duration": 4.24
    },
    {
      "text": "essentially did is is just it created",
      "start": 3184.839,
      "duration": 3.801
    },
    {
      "text": "these input output pairs but in a very",
      "start": 3186.92,
      "duration": 4.24
    },
    {
      "text": "structured manner why structured because",
      "start": 3188.64,
      "duration": 5.0
    },
    {
      "text": "we can Define many things we can Define",
      "start": 3191.16,
      "duration": 5.12
    },
    {
      "text": "things like stride batch size number of",
      "start": 3193.64,
      "duration": 5.199
    },
    {
      "text": "workers",
      "start": 3196.28,
      "duration": 2.559
    },
    {
      "text": "Etc uh so there are essentially three",
      "start": 3198.88,
      "duration": 4.08
    },
    {
      "text": "things which are very important for you",
      "start": 3201.359,
      "duration": 4.401
    },
    {
      "text": "to remember and let me take this example",
      "start": 3202.96,
      "duration": 5.399
    },
    {
      "text": "by rubbing some things of the screen so",
      "start": 3205.76,
      "duration": 5.4
    },
    {
      "text": "the first thing to remember is the uh",
      "start": 3208.359,
      "duration": 7.0
    },
    {
      "text": "stride so stride basically",
      "start": 3211.16,
      "duration": 7.28
    },
    {
      "text": "dictates here yeah so this this",
      "start": 3215.359,
      "duration": 4.801
    },
    {
      "text": "schematic here shows the difference",
      "start": 3218.44,
      "duration": 4.6
    },
    {
      "text": "between stride so if you see the top top",
      "start": 3220.16,
      "duration": 5.88
    },
    {
      "text": "level schematic here um this shows a",
      "start": 3223.04,
      "duration": 5.799
    },
    {
      "text": "stride of one which means that the input",
      "start": 3226.04,
      "duration": 5.16
    },
    {
      "text": "of batch one and batch two will just be",
      "start": 3228.839,
      "duration": 4.76
    },
    {
      "text": "differing by one word so there is a lot",
      "start": 3231.2,
      "duration": 3.84
    },
    {
      "text": "of overlap which might lead to",
      "start": 3233.599,
      "duration": 3.321
    },
    {
      "text": "overfitting what people people usually",
      "start": 3235.04,
      "duration": 3.68
    },
    {
      "text": "do is that they keep the stride length",
      "start": 3236.92,
      "duration": 3.919
    },
    {
      "text": "equal to the context length so that you",
      "start": 3238.72,
      "duration": 4.32
    },
    {
      "text": "don't even miss any word but there is",
      "start": 3240.839,
      "duration": 4.321
    },
    {
      "text": "not an overlap between different input",
      "start": 3243.04,
      "duration": 4.48
    },
    {
      "text": "batches that's the meaning of stride the",
      "start": 3245.16,
      "duration": 6.28
    },
    {
      "text": "second thing is the uh batch size so",
      "start": 3247.52,
      "duration": 6.48
    },
    {
      "text": "what the batch size lets you do is it",
      "start": 3251.44,
      "duration": 5.6
    },
    {
      "text": "tells the model how many batches of data",
      "start": 3254.0,
      "duration": 4.799
    },
    {
      "text": "you want to process at once before",
      "start": 3257.04,
      "duration": 4.88
    },
    {
      "text": "making the parameter updates so towards",
      "start": 3258.799,
      "duration": 4.8
    },
    {
      "text": "the end of this lecture we showed an",
      "start": 3261.92,
      "duration": 4.12
    },
    {
      "text": "example where the batch size was equal",
      "start": 3263.599,
      "duration": 3.681
    },
    {
      "text": "to 8",
      "start": 3266.04,
      "duration": 2.84
    },
    {
      "text": "which means that all these eight input",
      "start": 3267.28,
      "duration": 3.319
    },
    {
      "text": "output pairs will be processed before",
      "start": 3268.88,
      "duration": 3.959
    },
    {
      "text": "making the parameter updates and the",
      "start": 3270.599,
      "duration": 4.321
    },
    {
      "text": "last parameter which we did not explore",
      "start": 3272.839,
      "duration": 4.801
    },
    {
      "text": "too much is actually number of workers",
      "start": 3274.92,
      "duration": 4.8
    },
    {
      "text": "what this means is that you can exploit",
      "start": 3277.64,
      "duration": 4.479
    },
    {
      "text": "the parallel Computing facilities in",
      "start": 3279.72,
      "duration": 5.52
    },
    {
      "text": "your own computer because all of us have",
      "start": 3282.119,
      "duration": 5.121
    },
    {
      "text": "multiple threads on our computer so you",
      "start": 3285.24,
      "duration": 3.92
    },
    {
      "text": "can make sure the Computing happens on",
      "start": 3287.24,
      "duration": 5.04
    },
    {
      "text": "Parallel threads by specifying number of",
      "start": 3289.16,
      "duration": 5.6
    },
    {
      "text": "workers so what the data loader",
      "start": 3292.28,
      "duration": 4.279
    },
    {
      "text": "essentially does is that ultimately we",
      "start": 3294.76,
      "duration": 3.88
    },
    {
      "text": "can extract input output pairs through",
      "start": 3296.559,
      "duration": 4.24
    },
    {
      "text": "the first batch second batch Etc in the",
      "start": 3298.64,
      "duration": 4.6
    },
    {
      "text": "data loader and then this now will be",
      "start": 3300.799,
      "duration": 4.641
    },
    {
      "text": "converted into Vector embeddings which",
      "start": 3303.24,
      "duration": 5.16
    },
    {
      "text": "then we will feed into our model",
      "start": 3305.44,
      "duration": 5.44
    },
    {
      "text": "training the next section or the next",
      "start": 3308.4,
      "duration": 4.24
    },
    {
      "text": "lecture is going to be a token embedding",
      "start": 3310.88,
      "duration": 4.12
    },
    {
      "text": "or vector embedding I know everyone that",
      "start": 3312.64,
      "duration": 4.52
    },
    {
      "text": "today's lecture was a bit more complex",
      "start": 3315.0,
      "duration": 3.839
    },
    {
      "text": "especially because of the data set and",
      "start": 3317.16,
      "duration": 4.399
    },
    {
      "text": "data loader but this part is very rarely",
      "start": 3318.839,
      "duration": 5.2
    },
    {
      "text": "covered by anyone and I really wanted to",
      "start": 3321.559,
      "duration": 5.081
    },
    {
      "text": "make sure I cover it in a lot of detail",
      "start": 3324.039,
      "duration": 4.201
    },
    {
      "text": "thank you so much everyone I hope you",
      "start": 3326.64,
      "duration": 3.199
    },
    {
      "text": "are enjoying and understanding these",
      "start": 3328.24,
      "duration": 3.92
    },
    {
      "text": "lectures I'm deliberately making them a",
      "start": 3329.839,
      "duration": 4.48
    },
    {
      "text": "bit long so that everything is covered",
      "start": 3332.16,
      "duration": 4.439
    },
    {
      "text": "from scratch thanks everyone and I look",
      "start": 3334.319,
      "duration": 3.681
    },
    {
      "text": "forward to seeing you in the next",
      "start": 3336.599,
      "duration": 4.401
    },
    {
      "text": "lecture",
      "start": 3338.0,
      "duration": 3.0
    }
  ],
  "full_text": "[Music] hello everyone welcome to this lecture in the build large language models from scratch Series in the previous lecture we took a look at bite pair encoding and uh we saw that how bite pair encoding algorithm can be used for something which is called as subword tokenization so we saw the difference between word based subword based and character based tokenization and we looked in detail how GPT models such as GPT 2 3 and 4 use the bite pair encoding algorithm for tokenization if you have not seen the video for the previous lecture again I would highly ENC encourage you to go through this so that you will follow along pretty well in this lecture if you are coming to this playlist for the first time welcome and uh we follow a very specific style in this playlist where we do a mix of writing on the White board plus showing you everything from scratch in the jupyter notebook code editor so that the theoretical understanding is also strong and the coding background is also strong up till now we have looked at tokenization which is needed for large language models so if you think of the whole process we are currently at the data pre-processing stage before the data is given for the llm training in the pre-processing the first step is tokenization then we come to something called Vector embeddings we have not seen Vector embeddings yet uh and then after that we feed these Vector embeddings to the uh training or for the training process before we come to Vector embeddings there is one very important lecture which we need to cover and that is the topic of today's lecture creating input Target pairs essentially input output pairs if you look at other machine learning tasks such as classification ation it's usually usually very clear right what is the input and what is the output if you want to distinguish between cats and dogs from images the images of cats and the images of dogs will be input and whether it's a cat or whether it's a dog will be the output if you consider a regression problem on the other hand let's say if you want to predict the price of a house B based on its area the area of the houses is the input and the price is the output so creating the input output pairs or the input Target pairs is pretty easy for large language models we use a specific technique for creating these pairs and it's very important to devote a separate lecture for you to understand this so let's get started with today's lecture as I mentioned before now only one last step is remaining before we move to creating Vector embeddings which will then be fed to training the large language model and then last and then that last step is essentially create getting the input Target pairs so first when I say input Target pairs what do I mean and what do input Target pairs looks like so let's say uh this is my uh sentence right which is the text sample llms learn to predict one word at a time so the blocks which are marked in blue will be the input to the llm and the block which are marked in red will be the Target or the output which the llms have to learn and why are there these different rows so these are different iterations let's look at the first iteration in the first iteration the input is llm and the based on this input the out uh llm has to learn the output which is the learn so the next word is always the output whatever comes after the prediction is masked or it's not shown to the llm this is what happens in iteration number one now let's look at iteration number two so learn which was the output or the Target in the first iteration now is a part of the input so in the second iteration llms learn that is the input and two is the target that's the target pair that's the second iteration in the third iteration two which was the output of the previous iteration now becomes the input so so llms learn to is the input in the third iteration and predict is the output I hope you have started understanding the pattern now in every iteration there is only the next word which is the output and whatever comes before that is the input these are the input Target pairs that's very important to remember so uh here also you'll see that llms learn to predict is the input and one is the output so at every stage of the iteration process uh llms have input which is the part of the sentence up till the word which needs to be predicted and the word which needs to be predicted that is essentially the output this this figure which I'm saying is just for illustration purposes in today's lecture we'll learn something about context length which means how many words are given as the input the output length is always one one word will be predicted but we can essentially choose the input context length now uh in every iteration The Words which are after the target are essentially masked so the llms cannot access The Words which are past the target so there are two things to remember here the first thing to remember is that within the sentence itself we break down the sentence into input and a Target which is the next word uh then in the second thing to remember is that in subsequent iterations whatever was the output in the previous iteration then becomes the input so this is a auto regressive model why Auto regressive because the output of the first iteration becomes an input of the next iteration like let's look at these two iterations in in this iteration let me show it with a different color so that it becomes easy in this iteration one the result one was an output right but see in this iteration one is now a part of the input and then the next word is the output so it's called an auto regressive and it's also called a self-supervised learning or you can think of it as unsupervised learning itself because we are not labeling the input and the output the sentence structure itself uh is used to predict or is used to determine what is the input and the output we do not have to do any special labeling so in cats and dogs we have to manually label this is a cat this is a dog right for the image classification but here to create the input Target pairs we don't have to say that look this label this as the input label this as the output we'll just write a simple code which utilizes the sentence structure itself and breaks down the sentence into input and the output so this is also an example of unsupervised learning and it's also called Auto regressive I hope you have understood these two concepts so in pre-training we always do unsupervised learning because the sentence structure is exploited to create input output pairs or input Target pairs so I hope you have understood how the the input Target pairs look like and we are going to create this in today's lecture in Python uh if you understand up till this it's actually pretty easy to code it out in Python but I have I feel that students don't really understand this part intuitively and and hence they find the coding part of it a bit difficult okay now I want to mention a few things uh which I've just which just serve as a summary of what all I explained up till now the first thing is what we are essentially doing here is that we are given a text sample and uh based on the text sample we are extracting input blocks that serve as the input to the llm correct and the llm prediction task during the training is to predict the next word that follows the input block so for example if you're looking at this input block the llm task is to predict the output or the next word based on this input uh and that's what the llm is trained for and the last point to remember is that during the training process we will mask out all the words that are past the target so in every iteration the target is the target word right like in this iteration time or let me take an earlier iteration in this iteration two is the target so when we are doing this iteration the llm does not see anything which comes after two so this part is essentially masked and we'll see how to implement all of these features in code Okay so until now I just wanted to explain what is the purpose and what is the aim of today's lecture and now we are going to code the input Target pairs in Python so I hope you are ready for this coding so let's get started with coding great so this coding section I've have titled creating input Target pairs as always I'll be sharing this Jupiter notebook code also with you along with the video so that you can run the code and check check whether you have understood the concept or not yourself so in this section we are going to implement a data loader that fetches the input Target pairs using a sliding window approach so there are two parts of this sentence which might be confusing to you what is data loader that's part number one and what is the sliding window approach that's part number two don't worry I'll explain to you both of these in a lot of detail uh to get started what we will initi do is that we'll take the whole the verdict short story so remember our data set for this entire coding Journey for this entire playlist is this short story The Verdict let me show you uh how it actually looks like so this is the short story called The Verdict this is the data set which we have been using I think this was published in uh so let me check the verdict edit won it was published in 1908 and we are using using this as the data set it's a toy data set but it's important because whatever we learn right now it scales exactly the same way for larger data sets as well so we are going to use this data set and remember in the last lecture we looked at the bite pair encoding tokenizer we are going to encode this entire text using the bite pair encoding tokenizer it's a subword tokenizer so the tokens Can Be characters the token can be words the tokens can be subwords as well so if you if you are not familiar with the bite pair encoder please look at the previous lecture which we have covered great so we have uh defined the tokenizer already which is the bite pair encoder tokenizer and what we'll be first doing is we will read the entire data set and store it in a variable called raw text and then we will encode the entire raw text remember what an encoder does is takes this text and converts it into token IDs and let us actually run this right now so I ran this right now and you will see that uh I've have printed out the length of the encoded text which means it's 5145 that means the vocabulary size which we have is 5145 what does a vocabulary mean well we covered this in the previous lecture but let me show it to you again a vocabulary essentially looks something like this uh yeah so this is how let me go to the yeah this is how a vocabulary looks like like essentially we'll have different tokens and to every token a token ID will be uh attached so vocabulary is essentially dictionary which maps The Tokens into token IDs remember since we are using the bite pair encoder the tokens won't be words but they can be subwords or characters also so essentially what this size 5145 conveys is that our vocabulary for the for this text which we have as the data set has the length of 514 5 which means we have 5145 tokens and corresponding token IDs great so uh I have just written this in blue executing the code above will return 5145 that is the total number of tokens in the training set after applying the bite PA encoding tokenizer great so what I'm going to demonstrate right now to you is just I'm going to look at the first uh so what I'm going to do as I'm going to remove the first 50 tokens for the from the data set just so that the demonstration becomes a bit better uh after you remove the initial 50 tokens it results in a slightly more interesting text passage you can keep the entire tokens as well just to make the lecture more interesting what I'm going to do here is that the encoded tokens were in ENC or encoded unders scroll text so I'm going to Define one more variable called called encoded undor sample which just removes the first 50 tokens from the data set great now uh first I what I want you all to do is I want you to pause here for a moment and think about this question yourself uh think about the question that let's say you are given this data set right now and you you'll I hope you understood this input output Target pairs which I mentioned what's the simplest thing which comes to your mind how can you convert this data set into such kind of uh input output Target pairs what will you need to make this conversion can you think about it a bit think about the simplest way don't think about complex algorithms anything like that what is the simplest thing which comes to your mind you can pause the video here for some time because if you answer it it will really improve your understanding so let me reveal the answer now one of the easiest and most intuitive ways to create the input Ty Target pairs for the next word prediction task is to create two variables X and Y where X contains the input tokens and Y contains the targets which are essentially the input shifted by one so let me explain to you how this logic works okay so what do we exactly need here let's say if uh let's say if my input is 1 2 3 and 4 let's say say if my input is this I want my output array let's say if this is my input array X I want my output array to be looking something like 2 3 4 and 5 so what I have done here exactly is that if one is the input two should be the output it's very similar here if llm is the input learn should be the output correct if one and two is the input then three should be the output which means that if llm learn is the input then two should be the output if 1 2 3 are the input which means that if llms learn two is the input then the output should be four which means that predict should be the output and then finally if 1 2 3 4 if all of these four words are the input then five should be the output which means that if llm learn to predict is the input then the output should be equal to one this is what I actually want to create and how do I determine the size of this uh why do why did I take the input size X to be four and the output size to be four so basically that is called as the context size the context size is how many words do you want to give as input for the model to be making its prediction so here the context size is equal to four right so if we give up to four four words the model will be able to predict the next word that is what the context size actually means so we want to create input output arrays like this so let me show you how those can be created for this data set of the verdict which we have seen okay so first we have to determine the context size as I told you the context size determines how many tokens are included in the input so let me explain the context size a bit more here currently we are choosing context size of four you can choose anything which you want and you can play around with this code when I share it with you so the context size of four means that the model is trained to look at a sequence of four words or tokens to predict the next word in the sequence so the input X is the first four tokens let's say 1 2 3 4 and the target Y is the next four tokens which is 2 3 4 5 so that is meant by context size so the input if the input is 1 2 3 4 the output is 2 3 4 5 what does it mean if the input is one the output will be two if the input is 1 two the output will be three if the input is 1 2 3 the output will be four if the input is 1 2 3 4 the output will be five but the input cannot be one 2 3 4 5 because then the context size would be exceeded to think of it intuitively the context size is basically how many words the model should pay attention at one time to predict the next word so let's now take a simple thing so we have this encoded sample which contains the token IDs of the encoded data set what I will first do is that I will first take the four elements which are the first four elements that is my X which is the input and then I'll just shift this x Matrix X array by one and then that will be my Y which is the output so let's print out X so the IDS which are associated with the first four encoded samples are 290 4920 2241 and 287 and then the IDS which are associated with Y which is the output is 4920 2241 287 and 257 what does this mean if the input ID is 290 then the output will be 4920 if the input is 290 and 4920 the output is 2241 if the input is 290 4920 and 2241 the output will be 287 and if the input is 290 4920 2241 and 287 the output will be 257 this is how the input output pairs are actually constructed so uh what we can do now is that processing the inputs along with the targets and remember the targets are just the input shifted by one position we can then create the next word prediction tasks as follows so what I just explained to you I've written this in code so I have created two uh variables here called context and desired and I'm looping in so the context size is four so this Loop will go from 1 to five so in the when I is equal to 1 which is the first iteration the context will be just the first token ID which is 290 and the desired will be the next token ID which is 4920 awesome when I is equal to 2 then the context will be the first two tokens which is 290 and 4920 and the desired will be the next token which is 2241 if I is equal to 3 uh then the context would be the first three token IDs which are 290 4920 and 2241 and the output will be or the desired will be the next token which is 287 and if I is equal to 4 then the context will be the first four tokens IDs and the desired will be the next which is 257 so everything on the left of the arrow here refers to the input the large language model would receive uh and the token ID on the right hand side of the arrow represents the target token ID which the llm is supposed to predict so when we constructed these input output pairs this is what it actually means there are four prediction tasks here it's not one prediction task so when I created this input output pair of X and Y and even here here when I showed you the input output pair of X and Y it's not just one prediction task but there are four prediction tasks which are happening here and these are the four prediction tasks because the context size was four if the context size was eight there would have been eight prediction tasks in each input output pair so when you look at input output pairs usually regression and classification problem one input output pair corresponds to one prediction task image of a dog needs to be classified as whether it's a cat or a dog but in the case of llms one input output pair corresponds to the number of prediction tasks as set by the context size that is very important now what I'm going to do is that I'm going to take this simple the same code but I'm going to decode it into text so that you can get a feel of what is exactly happening here so here you can see I've taken the same code but I'm printing the decoded context and I'm printing the decoded desired value so if and is the input established is the output if and established is the input himself is the output if and established himself is the output the next word which is in is the output and if and established himself in is the input then the next word uh that is the output now this is exactly what we started the lecture with right you remember we started the lecture with this and uh now what we have done is that through code we have just created very simple input output pairs X and Y and we have seen how these pairs can be used to create the input and the output awesome right so this is just the first step of what we need to be doing what we have done so far is we have created the input output pairs that we can turn into use for the llm training so later we are going to do llm training and so we have created input output pairs now but we need to create them in a much more structured manner we need to create them for the entire data set not just that later we will parallel processing so if we have multiple CPUs and we need to do parallel Computing we need to do Computing in batches so we are going to do this in a very structured Manner and for that what we are going to be doing is we are going to use something called as uh data loader so now there is only one more task which is remaining before we can look at the vector embeddings in the next lecture and that is implementing an efficient data loader uh that iterates over the input data set and Returns the inputs and targets as P torch tensors So currently we have got the input output arrays right but they are not tensors why do we need tensors because all the optimization procedures which come later we we are going to use py torch and py torch works with tensors so we need input tensors and we need output tensors no need to worry if you don't know what a tensor is you can just think of it as a two-dimensional array for now or multi-dimensional array no need to worry about this this will not stop you from understanding this lecture so our goal is this we want to implement a data loader which creates two tensors an input tensor which contains the text that the llm sees and the target tensor that includes the targets for the llms to predict that's it basically we have to create something exactly like what I showed you in the code before but we need to create it in a tensor format and we need to do it in a structured manner so that's why we are going to use something called as data set and data loader so the these are data sets and data loaders which are in Python and here you can just see some examples which have been done for some classification data sets but essentially data sets and data loaders enable you to load or process the data in a much more efficient and compact manner as we'll see right now awesome so now what we are going to do in the next step is we are going to Implement a data loader and uh for the efficient data loader implementation we will use the pytorch inbuilt data set and data loader classes so these are the data set and data loader classes link which I've shown right now I'll also attach the link in the video description before going into the code further I just want to show you what we expect the data loader to do so that you have a visual understanding I have seen that until you get a visual understanding sending the code becomes very difficult to really Master but if you know what you want to implement it's really very easy so in this section what are we doing we are implementing a data loader that fetches the input output Target pairs using a sliding window approach let's see what this means so uh here so what we are going to do is that let's look at this sample text in the Heart of the City stood the old library A Relic from a Bagon era let's say this is the kind of sentence and we want to create input output Pairs and we are going to create input output pairs with a context size of four okay so let's say if the input is in the heart of let's say the input is in the heart of the output tensor will be shifted by one right as we already saw so the output will be the heart of the correct so the first input pair is in the heart of and the first output is the heart of the now in this input output pair there will be four prediction tasks the first is that if the input is in the prediction should be the if the input is in the the prediction should be heart uh let me switch to a different color if the input is in the heart the prediction should be off and if the input is in the heart of the prediction should be the so uh first of all we have an X which is the input tensor and Y which is the output tensor now let's see what the row of every tensor are representing uh so we collect the inputs in a tensor X so we collect the inputs in a tensor X where each row represents one input context so let's look at the tensor X if you see each row each row of this is one input context in the Heart of the City stood the so each row represents one uh input context so the first input output pair will be in the heart of and the first output will be the heart of Thee the second input will be the CT stood the and the second output will be CT stood the old so basically what I earlier in this lecture I showed you one input output pair when we look at tensors if you look at each row each row of the X tensor is an input each row of the Y tensor is the Corr oning output so the 50th row of the X X tensor and the 50th row of the Y tensor will be the 50th input output pair and in each input output pair there are four prediction tasks here as I as I told you because the context size is equal to four so essentially we are doing the same thing what we did in the earlier part of the lecture but we just take the entire text uh we put it in tensors in the rows of the tensor so we split the text into four words so the first four words are the first row the second four words are the second row and if you look at the output tensor it just the input tensor shifted by one that's it if you look at each row of the output tensor it's just the input tensor row shifted by one so the second tensor y uh the second tensor y contains the corresponding prediction targets next Words which are created by Shifting the input by one position this is very important for everyone who is watching this lecture to understand uh it all we are doing is next word prediction task so let me again explain this so that I I really want this concept to be understood because it's the heart of everything which we are going to do but let's look at the second row in the second row there will be four prediction tasks the first prediction task is when the input is the the output is City when the input is the city the output is stood when the input is the city stood the output is the and when the input is the city is stood the the output is the old the output is old so basically each input output pair corresponds to one prediction task and corresponds to four prediction tasks and we are just predicting the next word that's it it's as simple as that and that is exactly all we are actually doing in the code also so now I'm returning back to the code and uh This what I showed you here right now on the Whiteboard uh creating such kind of input tensor and output tensor is exactly what we are going to do in the code so if you if you have understood this the code will be much easier to understand so we are going to implement a data loader which creates these input and the output tensors and this will be done in four steps the first is tokenizing the entire text because uh we are going to deal with token IDs right now I'm showing you words over here but actually we'll deal with token IDs so we need the encoded text uh then we'll use a sliding window and now do you understand why is it called sliding window because uh look at this blue look at the blue window and the red window here so the blue is the input and then you slide it by one row slide it by one world and that's the output so each input and output pair is just sliding so you slide the input and then you get the output pair uh and then finally what we'll be doing is that we'll return the total number of rows in the data set and we'll return a single Row from the data set I'll show what this means so here we are going to define a class um and this class is going to take a data set now uh for this what we are doing is from tor. utils we are importing data set and data loader the data loader will come a later right now we have our goal is to define the data set and the data set cannot just be a bunch of tokens we need to make sure the data set is in input output pairs so what do we do here first we see what are the arguments which are taken when we create an instance of this class so when we create an instance of this class we basically need to specify four things we need to specify all the text file which we have so this is the data set the txt file then we need to specify the tokenizer so here we are using the bite pair tokenizer then we need to specify the max length the max length is the context size here we are going to use a context size or context length of four and then there is something called as stride so what stride means we'll come come to that in a moment but right now just know that there are four arguments which this class actually takes now what we'll be doing is that we'll be creating two arrays the first is called input IDs the second is called Target IDs what we'll be doing is that in input IDs uh we are so here you see we are going to uh loop over the entire data set so when I is equal to 1 the input ID the input chunk will have token IDs which are from 0 to 4 and the target will be token IDs from 1 to five which is just shifted by one and then you append this to the input ID's tensor and the target ID's tensor so when I is equal to one what will be appended is the first row of the input and the first row of the output so let me actually rub rub erase this a bit okay so in the code we saw the iterations right so when I is equal to 1 the first row will be appended to the input tensor and the first row will be appended to the output tensor so if you see the input ID is is the input tensor and this input chunk is being appended that's the first row now when I is equal to 1 we slide over to the next so if I is equal to one we uh we we look at the next chunk so the first chunk will be in the heart of in the heart of the second chunk here is the city stood the that's the third chunk the fourth chunk is old library a so we are going to divide the entire data set into chunks like this and then we are going to append that to the input tensor and just we are going to slide the chunk by one and then that we are going to up to the output tensor this is how we are creating the input and the output tensors and then we are going to Loop till we reach the end of the data set so length of data set minus the max length why minus max length because the last thing will include the context size and so we don't want to spill over the data set essentially if you are finding this section a bit hard to understand just remember that all we are doing here is that we have a data set we are chunking the data set so we have in first we have the input chunk and then we have the output chunk actually I think let me explain this using a Hands-On example over here so let's take this this example itself which I have written here right now uh what we are essentially doing here is that we are first going to have an input chunk so two Implement efficient data loaders that's my first input chunk then what I'm going to do then I'm going to shift it by right shift it to the right by one and then I'll have my output chunk so the output chunk is Implement efficient data loaders V so that's my first input output chunk so the input chunk will be the first row of the tensor the output chunk will be the second row of my tensor and then I'll slide so the way I'll slide will depend on my stride so if my stride is equal to let's say one it means that my next input will be Implement efficient data loaders and my next output will be sorry my next input will be Implement efficient data loaders V and my next output would be efficient data loaders V collect so at each time the output is just the input shifted by one and stride determines how much we slide so in the example which we took here if you see the in the first input is in the heart of but the second input is the city stood the so the first input is in the heart of the second is the city stood the which means that the stride is also equal to four so the first first input was this and then we moved and then the because the stride was four the second was the second input was the it stood the if the stride was equal to one the the next input would have been the heart of the city but that is not the second input here which means we have used a stride of four in this example that's why we also need the stride because we need to know how much to slide when to create the next input output batch I hope you have understood this part this is a bit of a tricky portion so please ask in the comment section if something is unclear over here so until this part we have created the input output tensor but now we have to define a method which is called as get item what this method does is that based on the index which we provide it just Returns the that particular row of the input and that particular row of the output so if the index is equal to zero this will return the first row of the input tensor and the first row of the output tensor why is this method get item needed because when we create a data loader the data loader will look at this method and then only it will create the input output pairs so if you look at the data loader what uh it needs the data set in this map style or the iterable style right now we are using a map style data set which means we need to have this get item what the get item will do is that it will actually tell it will tell the data loader uh what what kind of input and Target should we have so here we are clearly saying that if it's based on the index if the index is 50 the input will be the 50th row of the input tensor the target will be the 50th row of the output tensor so this G item is finally what the data loader will be using now let me recap what all we have learned so far so this GPT data set origin class we have just implemented is based on the pytor data set class it defines how individual rows are fetched from the data set each row consists of number of token IDs assigned to an input chunk tensor this basically means that each row the length of or the number of tokens in each row is equal to the context length so here if you see the number of tokens in each row in the heart of four tokens because the context size is four the target chunk tensor contains the corresponding targets so uh as I've mentioned over here I'll actually upload the links to this data set data loader and also maybe uh a small tutorial so that uh you know this thing becomes a bit more clearer and I think you should have a stronger understanding of uh this data set and data loader portion because many people just skip over this completely now what we'll be doing since our data set is ready and this format is ready we will feed the data set into the data loader so this is where the data loader comes into the picture and what we'll be doing is we'll be doing the four things we'll initialize the tokenizer create the data set why because this data set needs this class needs four attributes the the text the tokenizer the max length and the stride then what we'll be doing is that we'll put drop last equal to true because if the last batch it's shorter than the batch size uh it's dropped to prevent loss spikes during training you don't need to know about this too much but just remember that when we do batch processing if the last batch is shorter than the specified batch size uh it is important to prevent loss spikes during the training process awesome so now we Define this function called create data loader this is very important because this is the one this function will implement the batch processing the parallel processing which we will need uh and that is governed by the batch size but more than that what this function will do is that it will actually create uh it will help us create the input output uh data pairs from the data set which we defined earlier awesome so let's see the arguments which this function takes it of course takes the text file which is the data set which we have then it takes the batch size which is how many batches how many CPU processes we want to run parallell if you don't specify anything this will be by default four so if the number of threads on your CPU are four or eight you can run those many processes parallely max length is basically equal to the context length so we here I showed you a context length of four uh but when gpt2 or gpt3 those high level llm models are designed they usually Implement a context length of 256 which means they are so strong that the model can look at 256 words and predict the next word during training then stride is one 28 so stride as I mentioned is when we create input output batches how much we need to skip before we create the next batch a number of workers is also the number of CPU threads which we which we can run simultaneously awesome so the first thing which we do is Define the tokenizer and here we are using the tick token which is the bite pair encoder used by GPT and then we create the data set so here see we are creating an instance of this GPT data set V1 class which we defined over here uh and here we provide the input text the tokenizer is this tick token which is the bite pair encoding the max length is 256 and the stride is 128 awesome so an instance of the GPT data set one is created and we are calling it data set this data set is then feeded or loaded into the data loader look at this data loader method it's it's it takes the data set as an attribute basically what is happening in this step is that this data loader will just check this get item method in this in this class and then it will return the input output pairs basically based on what is mentioned in the get item that is exactly how it's going to work and then we just return the data loader which are the input output pairs that's it which is happening over here so uh essentially in this part what we did was we implemented a a data set which is a method or rather I would say it's a library python and then what we are going to do is that we also implemented the data loader so the data set was initially implemented and we created a class called GPT data set V1 an instance of this class was created and then it was fed to the data loader method what this method essentially did was it accessed the get item and then essentially what it's going to do it's just going to create those input output tensors which we have defined in the GPT data set V1 class why did we do this data loader between because it will really help us to do parallel processing and it can also uh analyze multiple batches at one time so here I want to explain the difference between batch size and number of workers so there is a difference between batch size and the number of workers batch size is basically the number of uh batches the model processes at once before updating its parameters so to make sure that the model updates its parameters quickly the data is usually chunked into batches so that after analyzing four batches in this case the model will update its parameters rather than going through the entire data set num workers is different it is basically for parallel processing on different threads of your CPU uh and data loader enables us to do all this if we did not do this then defining the batch size num workers would be very challenging now what we are going to do we are going to test the data loader with a batch size of one and a context size of four this will develop an intu of how the data set V1 class and the create data loader function work together so if you found the previous part a bit challenging to understand please try to focus on this part where we are going to show the Hands-On implementation of the data set class and the create data loader function so first what we do here we just read the text uh and then we are going to create a data loader and convert the data loader into python iterator to fetch the next entry in the data let me show you what this means so here what we are doing is we are going to create the data loader but with a batch size of one and a context size of four then what we are going to do we are going to iterate through the uh data loader and we are going to print the first batch and I I want to show you what this batch looks like so I'm just going to print this uh and here you see this is the printed answer so what the first batch basically gave me is the input tensor and the output tensor that's it so this is the input tensor and when you shift it by one you get the output tensor that's it essentially we did all this to get this input output pair which we had already seen before so if you look at the input output pair it's very similar to um the input output pair which we had looked at the beginning of this lecture so if you remember at the beginning of this lecture we had looked at this input output pair 1 2 3 4 uh and then 2 3 4 5 right what we have essentially obtained right now is exactly similar but through the data loader so it's much more structured and here we can specify a lot more parameters like batch size maximum length stride so here the stride is equal to one we uh we can even show you the effect of stride so let me actually show you the figure to explain uh what actually changing the stride really looks like so um here is the figure for explaining The Stride in some detail yeah okay so if you look at this figure okay so let's look at this figure the first part of this figure shows the input stride of uh one and the second part of this figure shows the input stride of four so if you look at the first figure the first input of batch the input of batch one is in the heart of and the input of batch two is the heart of the so see there is just a stride of one year between batches between inputs of different batches but if you look at the second figure the input of batch one is in the heart of which is this and then you stride by four 1 2 3 and four so the next input will be the city stood the see so typically a more stride means that you you move over the data in a faster Manner and so less computations will be there that's what you specify When you mention the stride so here stride is equal to one which which means that we'll be doing something very similar to uh what is mentioned in this uh example which I'm highlighting with a star right now awesome so here is how we create the input and output batches so what I want to mention here is that the first batch variable contains two tensors the first tensor stores the input token ID these and the second St tenser stores the target token IDs which are these and since the max length is set to four each of the two tensors contain four token IDs that is also very very important to remember note that an input size of four is relatively small uh or the context size it is common to train llms with input sizes or context sizes of at least 256 now you can also see the second batch see the second batch is 367 2885 and this is the output of the second batch so the second batch input is this the second batch output is this so if you compare the First with the second batch we can see that the second batch token IDs are just shifted with one position see this is the first batch input token IDs this is the second batch input token IDs now can you think what would be the stride in this case based on the explanation which I provided to you the stride will be equal to one because because if you look at the first input batch and the second input batch it just shifted by one um so the stride setting dictates the number of position the input shift across batches emulating a sliding window approach that's why it's called as the sliding window approach batch sizes of one such as we have sampled from the data loader so far are used for illustration purposes if you have previous experience with deep learning you may know that small batch sizes require less memory but lead to more noisy model updates just like in regular deep learning the batch size is a trade-off and hyperparameter to experiment when training llms so as I mentioned the batch size is number of data the model has to process before updating its parameters so if the batch size is very small the parameter updates will be very quick but the updates will be noisy if the batch size is very large the model will be going through the entire data set before or the model will be going through the large batch before making the update so the update will not be as noisy but it will take a lot of time so you need to make sure this hyper parameter is set correctly before we move on uh and end this lecture the last thing which I want to show you is the effect of batch size uh so let's actually take a brief look at that essentially uh what happens when the batch size is more than one so the batch size so here you see I'm creating a data loader with a batch size equal to 8 and then I'm running this so see the input tensor and the output tensor and here I'm also incre increasing the stride to four so if you look at the first input and the second input you will see that there is not an overlap because the side stride is equal to four and here the batch size is equal to eight so see the input has essentially eight uh input tensor has eight inputs which means the batch size equal to 8 and the output tensor will also have eight rows because the batch size is equal to eight so the model will essentially process this batch before making the parameter updates uh okay so now here you can see as I mentioned we have increased the stride to four this is to utilize the data set fully um we don't skip a single word but also avoid overlap between batches since more overlap could lead to increased overfitting so that is one advantage of having a more stride so here you see in these two examples if you look at the second if you look at the second example over here the stride is equal to four so there is no overlap between the input batch one and the input batch two which might be good for overfitting per uh which might be good to prevent overfitting whereas if you look look over here the stride is just equal to one so the input batch one and two have a lot of overlap that might lead to overfitting which is not great for training this actually brings us to the end of today's lecture where we covered number of things first we covered what does it mean to uh break down the text into input Target pairs input Target pairs are definitely needed for training of llms and we started with this example uh this example right here on the screen let me just take you to that yeah so we started with yeah so we started with this example to illustratively explain what the input Target pair looks like so the target pair is just the input which is shifted by one then we saw how to convert this into X and Y pairs so if the input is 1 2 3 4 the output is 2 3 4 5 here the context size is four which means that if one is the input the output should be two if one and two is the input the output should be three if 1 2 3 is the input the output should be four if 1 2 3 4 is the input the output should be five so in one input Target pair there are four computations or four predictions because the context size is four the rest of the lecture was devoted to creating input Target pairs like this but in a structured manner for that what we actually did was we used something which is called as data loader and then we paired the data loader with the data set so first we created this GPT data set V1 class uh we created a data set and then we fed that data set into the data loader what this data loer essentially did is is just it created these input output pairs but in a very structured manner why structured because we can Define many things we can Define things like stride batch size number of workers Etc uh so there are essentially three things which are very important for you to remember and let me take this example by rubbing some things of the screen so the first thing to remember is the uh stride so stride basically dictates here yeah so this this schematic here shows the difference between stride so if you see the top top level schematic here um this shows a stride of one which means that the input of batch one and batch two will just be differing by one word so there is a lot of overlap which might lead to overfitting what people people usually do is that they keep the stride length equal to the context length so that you don't even miss any word but there is not an overlap between different input batches that's the meaning of stride the second thing is the uh batch size so what the batch size lets you do is it tells the model how many batches of data you want to process at once before making the parameter updates so towards the end of this lecture we showed an example where the batch size was equal to 8 which means that all these eight input output pairs will be processed before making the parameter updates and the last parameter which we did not explore too much is actually number of workers what this means is that you can exploit the parallel Computing facilities in your own computer because all of us have multiple threads on our computer so you can make sure the Computing happens on Parallel threads by specifying number of workers so what the data loader essentially does is that ultimately we can extract input output pairs through the first batch second batch Etc in the data loader and then this now will be converted into Vector embeddings which then we will feed into our model training the next section or the next lecture is going to be a token embedding or vector embedding I know everyone that today's lecture was a bit more complex especially because of the data set and data loader but this part is very rarely covered by anyone and I really wanted to make sure I cover it in a lot of detail thank you so much everyone I hope you are enjoying and understanding these lectures I'm deliberately making them a bit long so that everything is covered from scratch thanks everyone and I look forward to seeing you in the next lecture"
}